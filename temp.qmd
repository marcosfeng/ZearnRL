---
title: "Initial Analyses for RL model selection"
format:
  pdf:
    include-in-header: 
      text: |
        \usepackage{typearea}
author:
  - name: Marcos Gallo
bibliography: zearnrefs.bib
execute:
  echo: false
  warning: false
  error: false
knitr:
  opts_chunk:
    cache.extra: set.seed(832399554)
---

```{r load packages}
library(data.table)
library(tidyverse)
library(ggpubr)
library(ggforce)
library(gridExtra)
library(scales)
library(gtsummary)
library(gtExtras)
library(PerformanceAnalytics)
library(doParallel)
library(foreach)
library(reticulate)
library(cmdstanr)
library(brms)
```

```{r}
set.seed(832399554)
random_py <- import("random")
random_py$seed(832399554)
# https://www.random.org/integers/
# Timestamp: 2023-05-17 16:18:28 UTC
```

# Results

```{r load dimension reduction}
#| include: false
df <- read.csv(file = "./Bayesian/df.csv") %>%
    mutate(across(where(is.numeric),
                  ~ ifelse(. < .Machine$double.eps, 0, .)))
# Clean environment
rm(list = setdiff(ls(), c("df", "random_py")))
gc(verbose = FALSE)
```

```{r helper-functions}

get_lag_value <- function(datatable, col, lag_period, n_comp = NULL) {
  # Add a column for week_lag
  datatable[, week_lag := c(0, diff(week)), by = Classroom.ID]

  if (is.null(n_comp)) {
    # Update the lag column with shift function
    datatable[, (paste0(col, "_", lag_period)) :=
                shift(get(col), lag_period, fill = 0, type = "lag"),
              by = Classroom.ID]
  } else {
    for (comp in 1:n_comp) {
      # Update the lag column with shift function
      datatable <- datatable[, (paste0(col, comp, "_", lag_period)) :=
                              shift(get(paste0(col, comp)), lag_period, fill = 0, type = "lag"),
                            by = Classroom.ID]
    }
  }
  
  return(datatable)
}

# Function to identify high-density regions for a given vector of values
find_hdr <- function(values) {
  IQR <- quantile(values, 0.75) - quantile(values, 0.25)
  return(c(quantile(values, 0.25) - 1.5*IQR,
           quantile(values, 0.75) + 1.5*IQR))
}

in_hdr <- function(values) {
  hdr <- find_hdr(values)
  return(hdr[1] <= values & values <= hdr[2])
}

```

```{r panel-model}
#| eval: false

library(fixest)

create_model <- function(formula, data) {
  # Fit a logistic regression model with fixed effects
  model <- feglm(formula, data = data, family = binomial)
  return(model)
}

create_formula <- function(action, reward, state = NULL, lag = 1) {
  terms <- c()

  for (i in 1:lag) {
    terms <- c(terms, paste0(reward, "_", i))
    terms <- c(terms, paste0(action, "_", i))
    # Interaction term for reward_i * action_i
    terms <- c(terms, paste0(reward, "_", i, ":", action, "_", i))
    if (i != lag) {
      for (j in (i + 1):lag) {
        # Interaction for reward_i * action_j when i < lag
        terms <- c(terms, paste0(reward, "_", i, ":", action, "_", j))
        
      }
    }
  }

  if (is.null(state)) {
    formula_string <- paste0(action, " ~ ",
                             paste(terms, collapse = " + "),
                             " + week_lag | ", # Adding fixed effects part
                             "Teacher.User.ID + week")
  } else {
    formula_string <- paste0(action, " ~ ",
                             paste(terms, collapse = " + "),
                             " + ", paste0(state, "_1"),
                             " + ", paste0(state, "_1", ":",
                                           action, "_", (2:max(lag,2)),
                                           collapse = " + "),
                             " + week_lag | ",
                             "Teacher.User.ID + week")
  }
  return(formula_string)
}
#-------------
lags <- c(1:6)
n_comp = 4
n_lags = max(lags)
# Use map to iterate over methods, paste0 to concatenate strings
action <- c("Frobenius.NNDSVD_teacher")
reward <- c("Frobenius.NNDSVD_student")
# Estimation
params <- crossing(
  act = colnames(df)[str_detect(colnames(df), paste0(action, collapse = "|"))],
  lag = lags,
  # st  = colnames(df)[str_detect(colnames(df), paste0(reward, collapse = "|"))],
  rwd = colnames(df)[str_detect(colnames(df), paste0(reward, collapse = "|"))]
) %>%
  # filter(rwd != st) %>%
  unique()

# Data and Variables
df_bin <- as.data.table(
  df %>%
    mutate(across(dplyr::starts_with(action),
                  ~ if_else( . > median(., na.rm = TRUE), 1, 0))) %>%
    arrange(Classroom.ID, week) %>%
    ungroup()
)

# Create lags
for (col in c(action, reward)) {
  for (lag_period in 1:n_lags) {
    df_bin <- get_lag_value(df_bin, col, lag_period, n_comp)
  }
}

# Panel data
train_data <- as.data.frame(df_bin[set == "train"])
test_data <- as.data.frame(df_bin[set == "test"])

# Estimation
# Clean environment
rm(list = setdiff(ls(), c("df", "params", "train_data", "test_data",
                          "bic_plm", "compute_nloglik","create_formula",
                          "create_model", "get_lag_value", "model_selection")))
gc(verbose = FALSE)

cl <- makeCluster(detectCores()-1)
registerDoParallel(cl)
results <- foreach(i = 1:nrow(params),
                   .multicombine = TRUE,
                   .errorhandling = "remove",
                   .noexport = c("formula", "model",
                                 "residuals", "predictions"),
                   .packages = c("fixest", "pROC")) %dopar% {
                     act <- as.character(params$act[i])
                     lag <- params$lag[i]
                     # st <- as.character(params$st[i])
                     st <- NULL
                     rwd <- as.character(params$rwd[i])
                     fmla <- create_formula(action = act, reward = rwd,
                                            state = st, lag = lag)
                     model <- create_model(as.formula(fmla), train_data)

                     # Out of Sample Log Likelihood
                     predictions <- predict(model, newdata = test_data)

                     # Return the results as a list
                     list(Method = act,
                          Lag = lag,
                          # State = st,
                          Reward = rwd,
                          formula = fmla,
                          AUC = as.numeric(
                            roc(response = test_data[,act],
                                predictor = predictions)$auc
                          ),
                          bic = BIC(model),
                          fecoef = summary(model)$coeftable,
                          recoef = fixef(model))
                   }
# Stop the cluster
stopCluster(cl)
rm(cl)

save(results, file = "fe-results.RData")

```

```{r panel-model-states}
#| eval: false

#-------------
lags <- c(1:6)
n_comp = 4
n_lags = max(lags)
# Use map to iterate over methods, paste0 to concatenate strings
action <- c("Frobenius.NNDSVD_teacher")
reward <- c("Frobenius.NNDSVD_student")
# Estimation
params <- crossing(
  act = colnames(df)[str_detect(colnames(df), paste0(action, collapse = "|"))],
  lag = lags,
  st  = colnames(df)[str_detect(colnames(df), paste0(reward, collapse = "|"))],
  rwd = colnames(df)[str_detect(colnames(df), paste0(reward, collapse = "|"))]
) %>%
  filter(rwd != st) %>%
  unique()

# Data and Variables
df_bin <- as.data.table(
  df %>%
    mutate(across(dplyr::starts_with(action),
                  ~ if_else( . > median(., na.rm = TRUE), 1, 0))) %>%
    arrange(Classroom.ID, week) %>%
    ungroup()
)

# Create lags
for (col in c(action, reward)) {
  for (lag_period in 1:n_lags) {
    df_bin <- get_lag_value(df_bin, col, lag_period, n_comp)
  }
}

# Panel data
train_data <- as.data.frame(df_bin[set == "train"])
test_data <- as.data.frame(df_bin[set == "test"])

# Estimation
# Clean environment
rm(list = setdiff(ls(), c("df", "params", "train_data", "test_data",
                          "bic_plm", "compute_nloglik","create_formula",
                          "create_model", "get_lag_value", "model_selection")))
gc(verbose = FALSE)

cl <- makeCluster(detectCores()-1)
registerDoParallel(cl)
results <- foreach(i = 1:nrow(params),
                   .multicombine = TRUE,
                   .errorhandling = "remove",
                   .noexport = c("formula", "model",
                                 "residuals", "predictions"),
                   .packages = c("fixest", "pROC")) %dopar% {
                     act <- as.character(params$act[i])
                     lag <- params$lag[i]
                     st <- as.character(params$st[i])
                     rwd <- as.character(params$rwd[i])
                     fmla <- create_formula(action = act, reward = rwd,
                                            state = st, lag = lag)
                     model <- create_model(as.formula(fmla), train_data)

                     # Out of Sample Log Likelihood
                     predictions <- predict(model, newdata = test_data)

                     # Return the results as a list
                     list(Method = act,
                          Lag = lag,
                          State = st,
                          Reward = rwd,
                          formula = fmla,
                          AUC = as.numeric(
                            roc(response = test_data[,act],
                                predictor = predictions)$auc
                          ),
                          bic = BIC(model),
                          fecoef = summary(model)$coeftable,
                          recoef = fixef(model))
                   }
# Stop the cluster
stopCluster(cl)
rm(cl)

save(results, file = "fe-state-results.RData")

```

We first explore reinforcement learning (RL)-like characteristics within the teacher and classroom usage data. We aimed to uncover patterns indicative of RL, where actors (teachers) select actions (teaching strategies) that historically yield higher rewards (improved student outcomes) and use states (classroom contexts) as signals for action selection. Further, we sought to understand how actions contribute to achieving or maintaining desired states and the extent to which actions exhibit auto-correlation due to incremental learning processes.

## Model Fit and Performance

In order to capture the temporal dynamics of actions influenced by lagged rewards and states, we employed panel logistic regression models across different combinations of variables and lags. We incorporate lagged variables (ranging from one to six weeks) into the models using the Dynamic Analysis approach proposed to account for temporal autocorrelation and potential delayed effects. We applied reward and state structures extracted from classroom data via non-negative matrix factorization (NMF) with the Frobenius Non-negative Double Singular Value Decomposition (NNDSVD), and actions derived similarly from teacher data. We evaluate these models on the Bayesian Information Criterion (BIC) for model complexity and fit and the Area Under the Receiver Operating Characteristic curve (AUC) for predictive accuracy.

### Temporal Dynamics

Our investigation into temporal dynamics confirmed the impact of lagged rewards and actions on decision-making, embodying a foundational RL principle: shaping future decisions by past experiences. @fig-panel-bic illustrates this relationship, showcasing the predictive accuracy and model fit across different lag models, with a clear preference for a lag of two periods as optimal, based on the "elbow" in the AUC curves and the minima in BIC curves. This finding underscores the significance of immediate and preceding influences on future actions, aligning with the delayed reinforcement principle in RL.

```{r}
#| label: fig-panel-bic
#| fig-cap: "Average BIC and AUC across Lags"
#| fig-subcap: 
#|   - "BIC state-free"
#|   - "AUC state-free"
#|   - "BIC state-dependent"
#|   - "AUC state-dependent"
#| layout-ncol: 2

load("fe-results.RData")

fe_results_df <- do.call(rbind, lapply(results, function(x) {
  data.frame(
    Method = x$Method,
    Lag = x$Lag,
    State = "None",
    Reward = x$Reward,
    auc = x$AUC,
    bic = x$bic,
    stringsAsFactors = FALSE
  )
}))

teachers <- Reduce(intersect, sapply(results, function(x) {
  names(x$recoef$Teacher.User.ID)
}))

results_df <- do.call(rbind, lapply(results, function(x) {
  data.frame(
    Method = x$Method,
    Lag = x$Lag,
    # State = x$State,
    Reward = x$Reward,
    auc = x$AUC,
    bic = x$bic,
    stringsAsFactors = FALSE
  )
})) %>%
  group_by(Method, Reward) %>%
  mutate(bic_base = bic[which(Lag == 1)],
         bic = bic - bic_base,
         auc_base = auc[which(Lag == 1)],
         auc = auc - auc_base) %>%
  ungroup()

results_df_se <- results_df %>%
  group_by(Lag) %>%
  summarise(se_bic = sd(bic, na.rm = TRUE) / sqrt(n()),
            bic = mean(bic, na.rm = TRUE),
            se_auc = sd(auc, na.rm = TRUE) / sqrt(n()),
            auc = mean(auc, na.rm = TRUE))

generate_plots_with_se <- function(data, data_se, metric_name, metric_se_name) {
  y_label <- switch(metric_name,
                    "bic" = "BIC",
                    "auc" = "AUC")
  
  plot <- ggplot() +
    geom_line(data = data, aes(x = Lag, y = !!sym(metric_name),
                               group = interaction(Reward, Method),
                               # group = interaction(State, Reward, Method),
                               color = Method),
              linewidth = 0.3) +
    geom_ribbon(data = data_se,
                aes(x = Lag, ymin = !!sym(metric_name) - !!sym(metric_se_name),
                    ymax = !!sym(metric_name) + !!sym(metric_se_name)),
                fill = "lightblue", alpha = 0.3) +
    geom_line(data = data_se,
              aes(x = Lag, y = !!sym(metric_name)),
              linewidth = 1, color = "blue") +
    theme_minimal() +
    labs(y = y_label, x = "Lag") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1),
          legend.title = element_blank(),
          legend.position = "none")
  return(plot)
}

# Example usage for plotting Average BIC with Standard Error
bic_plot_se <- generate_plots_with_se(results_df, results_df_se, "bic", "se_bic")
auc_plot_se <- generate_plots_with_se(results_df, results_df_se, "auc", "se_auc")

#------------------

load("fe-state-results.RData")

fe_results_df <- fe_results_df %>%
  rbind(
    do.call(rbind, lapply(results, function(x) {
      data.frame(
        Method = x$Method,
        Lag = x$Lag,
        State = x$State,
        Reward = x$Reward,
        auc = x$AUC,
        bic = x$bic,
        stringsAsFactors = FALSE
        )
      }))
    )

teachers <- intersect(
  teachers, Reduce(intersect, sapply(results, function(x) {
    names(x$recoef$Teacher.User.ID)
    }))
  )

results_df <- do.call(rbind, lapply(results, function(x) {
  data.frame(
    Method = x$Method,
    Lag = x$Lag,
    State = x$State,
    Reward = x$Reward,
    auc = x$AUC,
    bic = x$bic,
    stringsAsFactors = FALSE
  )
})) %>%
  group_by(Method, Reward, State) %>%
  mutate(bic_base = bic[which(Lag == 1)],
         bic = bic - bic_base,
         auc_base = auc[which(Lag == 1)],
         auc = auc - auc_base) %>%
  ungroup()

results_df_se <- results_df %>%
  group_by(Lag) %>%
  summarise(se_bic = sd(bic, na.rm = TRUE) / sqrt(n()),
            bic = mean(bic, na.rm = TRUE),
            se_auc = sd(auc, na.rm = TRUE) / sqrt(n()),
            auc = mean(auc, na.rm = TRUE))

generate_plots_with_se <- function(data, data_se, metric_name, metric_se_name) {
  y_label <- switch(metric_name,
                    "bic" = "BIC",
                    "auc" = "AUC")
  
  plot <- ggplot() +
    geom_line(data = data, aes(x = Lag, y = !!sym(metric_name),
                               group = interaction(State, Reward, Method),
                               color = Method),
              linewidth = 0.3) +
    geom_ribbon(data = data_se,
                aes(x = Lag, ymin = !!sym(metric_name) - !!sym(metric_se_name),
                    ymax = !!sym(metric_name) + !!sym(metric_se_name)),
                fill = "lightblue", alpha = 0.3) +
    geom_line(data = data_se,
              aes(x = Lag, y = !!sym(metric_name)),
              linewidth = 1, color = "blue") +
    theme_minimal() +
    labs(y = y_label, x = "Lag") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1),
          legend.title = element_blank(),
          legend.position = "none")
  return(plot)
}

# Example usage for plotting Average BIC with Standard Error
bic_plot_se_st <- generate_plots_with_se(results_df, results_df_se, "bic", "se_bic")
auc_plot_se_st <- generate_plots_with_se(results_df, results_df_se, "auc", "se_auc")

#----------------

bic_plot_se
auc_plot_se
bic_plot_se_st
auc_plot_se_st

```


```{r panel-model-subset}
#| eval: false

library(fixest)

create_model <- function(formula, data) {
  # Fit a logistic regression model with fixed effects
  model <- feglm(formula, data = data, family = binomial)
  return(model)
}

create_formula <- function(action, reward, state = NULL) {
  terms <- c()

  # Interaction term for reward_i * action_i
  terms <- c(terms, paste0(reward, "_1"))
  terms <- c(terms, paste0(action, "_1"))
  terms <- c(terms, paste0(reward, "_1:", action, "_1"))
  
  terms <- c(terms, paste0(reward, "_1:", action, "_2"))
  terms <- c(terms, paste0(reward, "_2"))
  terms <- c(terms, paste0(action, "_2"))
  terms <- c(terms, paste0(reward, "_2:", action, "_2"))

  if (is.null(state)) {
    formula_string <- paste0(action, " ~ ",
                             paste(terms, collapse = " + "),
                             " + week_lag | ", # Adding fixed effects part
                             "Teacher.User.ID + week")
  } else {
    formula_string <- paste0(action, " ~ ",
                             paste(terms, collapse = " + "),
                             " + ", paste0(state, "_1"),
                             " + ", paste0(state, "_1", ":", action, "_2"),
                             " + week_lag | ",
                             "Teacher.User.ID + week")
  }
  return(formula_string)
}
#-------------
lags <- 2
n_comp = 4
n_lags = max(lags)
# Use map to iterate over methods, paste0 to concatenate strings
action <- c("Frobenius.NNDSVD_teacher")
reward <- c("Frobenius.NNDSVD_student")
# Estimation
params <- crossing(
  act = colnames(df)[str_detect(colnames(df), paste0(action, collapse = "|"))],
  lag = lags,
  # st  = colnames(df)[str_detect(colnames(df), paste0(reward, collapse = "|"))],
  rwd = colnames(df)[str_detect(colnames(df), paste0(reward, collapse = "|"))]
) %>%
  # filter(rwd != st) %>%
  unique()

# Data and Variables
df_bin <- as.data.table(
  df %>%
    mutate(across(dplyr::starts_with(action),
                  ~ if_else( . > median(., na.rm = TRUE), 1, 0))) %>%
    arrange(Classroom.ID, week) %>%
    # Filter out Classroom.IDs where any relevant variable has sd = 0
    group_by(Classroom.ID) %>%
    filter(Teacher.User.ID %in% teachers) %>%
    ungroup()
)

# Create lags
for (col in c(action, reward)) {
  for (lag_period in 1:n_lags) {
    df_bin <- get_lag_value(df_bin, col, lag_period, n_comp)
  }
}

# Panel data
train_data <- as.data.frame(df_bin[set == "train"])
test_data <- as.data.frame(df_bin[set == "test"])

# Estimation
# Clean environment
rm(list = setdiff(ls(), c("df", "params", "train_data", "test_data", "teachers",
                          "bic_plm", "compute_nloglik","create_formula",
                          "create_model", "get_lag_value", "model_selection")))
gc(verbose = FALSE)

cl <- makeCluster(detectCores()-1)
registerDoParallel(cl)
results <- foreach(i = 1:nrow(params),
                   .multicombine = TRUE,
                   .errorhandling = "remove",
                   .noexport = c("formula", "model",
                                 "residuals", "predictions"),
                   .packages = c("fixest", "pROC")) %dopar% {
                     act <- as.character(params$act[i])
                     lag <- params$lag[i]
                     # st <- as.character(params$st[i])
                     st <- NULL
                     rwd <- as.character(params$rwd[i])
                     fmla <- create_formula(action = act, reward = rwd,
                                            state = st)
                     model <- create_model(as.formula(fmla), train_data)

                     # Out of Sample Log Likelihood
                     predictions <- predict(model, newdata = test_data)

                     # Return the results as a list
                     list(Method = act,
                          Lag = lag,
                          # State = st,
                          Reward = rwd,
                          formula = fmla,
                          AUC = as.numeric(
                            roc(response = test_data[,act],
                                predictor = predictions)$auc
                          ),
                          bic = BIC(model),
                          fecoef = summary(model)$coeftable,
                          recoef = fixef(model))
                   }
# Stop the cluster
stopCluster(cl)
rm(cl)

save(results, file = "fe-subset-results.RData")

```

```{r panel-model-states-subset}
#| eval: false

#-------------
lags <- 2
n_comp = 4
n_lags = max(lags)
# Use map to iterate over methods, paste0 to concatenate strings
action <- c("Frobenius.NNDSVD_teacher")
reward <- c("Frobenius.NNDSVD_student")
# Estimation
params <- crossing(
  act = colnames(df)[str_detect(colnames(df), paste0(action, collapse = "|"))],
  lag = lags,
  st  = colnames(df)[str_detect(colnames(df), paste0(reward, collapse = "|"))],
  rwd = colnames(df)[str_detect(colnames(df), paste0(reward, collapse = "|"))]
) %>%
  filter(rwd != st) %>%
  unique()

# Data and Variables
df_bin <- as.data.table(
  df %>%
    mutate(across(dplyr::starts_with(action),
                  ~ if_else( . > median(., na.rm = TRUE), 1, 0))) %>%
    arrange(Classroom.ID, week) %>%
    # Filter out Classroom.IDs where any relevant variable has sd = 0
    group_by(Classroom.ID) %>%
    filter(Teacher.User.ID %in% teachers) %>%
    ungroup()
)

# Create lags
for (col in c(action, reward)) {
  for (lag_period in 1:n_lags) {
    df_bin <- get_lag_value(df_bin, col, lag_period, n_comp)
  }
}

# Panel data
train_data <- as.data.frame(df_bin[set == "train"])
test_data <- as.data.frame(df_bin[set == "test"])

# Estimation
# Clean environment
rm(list = setdiff(ls(), c("df", "params", "train_data", "test_data", "teachers",
                          "bic_plm", "compute_nloglik","create_formula",
                          "create_model", "get_lag_value", "model_selection")))
gc(verbose = FALSE)

cl <- makeCluster(detectCores()-1)
registerDoParallel(cl)
results <- foreach(i = 1:nrow(params),
                   .multicombine = TRUE,
                   .errorhandling = "remove",
                   .noexport = c("formula", "model",
                                 "residuals", "predictions"),
                   .packages = c("fixest", "pROC")) %dopar% {
                     act <- as.character(params$act[i])
                     lag <- params$lag[i]
                     st <- as.character(params$st[i])
                     rwd <- as.character(params$rwd[i])
                     fmla <- create_formula(action = act, reward = rwd,
                                            state = st)
                     model <- create_model(as.formula(fmla), train_data)

                     # Out of Sample Log Likelihood
                     predictions <- predict(model, newdata = test_data)

                     # Return the results as a list
                     list(Method = act,
                          Lag = lag,
                          State = st,
                          Reward = rwd,
                          formula = fmla,
                          AUC = as.numeric(
                            roc(response = test_data[,act],
                                predictor = predictions)$auc
                          ),
                          bic = BIC(model),
                          fecoef = summary(model)$coeftable,
                          recoef = fixef(model))
                   }
# Stop the cluster
stopCluster(cl)
rm(cl)

save(results, file = "fe-state-subset-results.RData")

```


```{r panel-model-restricted}
#| eval: false

library(fixest)

create_model <- function(formula, data) {
  # Fit a logistic regression model with fixed effects
  model <- feglm(formula, data = data, family = binomial)
  return(model)
}

create_formula <- function(action, reward, state = NULL) {
  terms <- c()

  # Interaction term for reward_i * action_i
  terms <- c(terms, paste0(reward, "_1"))
  terms <- c(terms, paste0(action, "_2"))
  terms <- c(terms, paste0(reward, "_1:", action, "_2"))
  terms <- c(terms, paste0(action, "_1"))

  if (is.null(state)) {
    formula_string <- paste0(action, " ~ ",
                             paste(terms, collapse = " + "),
                             " + week_lag | ", # Adding fixed effects part
                             "Teacher.User.ID + week")
  } else {
    formula_string <- paste0(action, " ~ ",
                             paste(terms, collapse = " + "),
                             " + ", paste0(state, "_1"),
                             " + ", paste0(state, "_1", ":", action, "_2"),
                             " + week_lag | ",
                             "Teacher.User.ID + week")
  }
  return(formula_string)
}
#-------------
lags <- 2
n_comp = 4
n_lags = max(lags)
# Use map to iterate over methods, paste0 to concatenate strings
action <- c("Frobenius.NNDSVD_teacher")
reward <- c("Frobenius.NNDSVD_student")
# Estimation
params <- crossing(
  act = colnames(df)[str_detect(colnames(df), paste0(action, collapse = "|"))],
  lag = lags,
  # st  = colnames(df)[str_detect(colnames(df), paste0(reward, collapse = "|"))],
  rwd = colnames(df)[str_detect(colnames(df), paste0(reward, collapse = "|"))]
) %>%
  # filter(rwd != st) %>%
  unique()

# Data and Variables
df_bin <- as.data.table(
  df %>%
    mutate(across(dplyr::starts_with(action),
                  ~ if_else( . > median(., na.rm = TRUE), 1, 0))) %>%
    arrange(Classroom.ID, week) %>%
    # Filter out Classroom.IDs where any relevant variable has sd = 0
    group_by(Classroom.ID) %>%
    filter(Teacher.User.ID %in% teachers) %>%
    ungroup()
)

# Create lags
for (col in c(action, reward)) {
  for (lag_period in 1:n_lags) {
    df_bin <- get_lag_value(df_bin, col, lag_period, n_comp)
  }
}

# Panel data
train_data <- as.data.frame(df_bin[set == "train"])
test_data <- as.data.frame(df_bin[set == "test"])

# Estimation
# Clean environment
rm(list = setdiff(ls(), c("df", "params", "train_data", "test_data", "teachers",
                          "bic_plm", "compute_nloglik","create_formula",
                          "create_model", "get_lag_value", "model_selection")))
gc(verbose = FALSE)

cl <- makeCluster(detectCores()-1)
registerDoParallel(cl)
results <- foreach(i = 1:nrow(params),
                   .multicombine = TRUE,
                   .errorhandling = "remove",
                   .noexport = c("formula", "model",
                                 "residuals", "predictions"),
                   .packages = c("fixest", "pROC")) %dopar% {
                     act <- as.character(params$act[i])
                     lag <- params$lag[i]
                     # st <- as.character(params$st[i])
                     st <- NULL
                     rwd <- as.character(params$rwd[i])
                     fmla <- create_formula(action = act, reward = rwd,
                                            state = st)
                     model <- create_model(as.formula(fmla), train_data)

                     # Out of Sample Log Likelihood
                     predictions <- predict(model, newdata = test_data)

                     # Return the results as a list
                     list(Method = act,
                          Lag = lag,
                          # State = st,
                          Reward = rwd,
                          formula = fmla,
                          AUC = as.numeric(
                            roc(response = test_data[,act],
                                predictor = predictions)$auc
                          ),
                          bic = BIC(model),
                          fecoef = summary(model)$coeftable,
                          recoef = fixef(model))
                   }
# Stop the cluster
stopCluster(cl)
rm(cl)

save(results, file = "fe-restricted-results.RData")

```

```{r}
#| label: tbl-fe-results-statefree
#| tbl-cap: "State-Free Panel Logistic Regression Results"

# Load the results from both subset and restricted analyses
load("fe-subset-results.RData")
original_results <- results
load("fe-restricted-results.RData")
restricted_results <- results

# Combine the model stats from original and restricted results for comparison
original_models <- do.call(rbind, lapply(original_results, function(x) {
  if (x$Lag != 2) return(NULL)
  data.frame(
    Action = x$Method,
    Reward = x$Reward,
    AUC = x$AUC,
    BIC = x$bic,
    Type = "Original"
  )
}))

# Select top 2 AUC models and top 2 BIC models for both original and restricted
top_models <- original_models %>%
  arrange(desc(AUC)) %>%
  slice_head(n = 2)
top_models <- original_models %>%
  arrange(BIC) %>%
  slice_head(n = 2) %>%
  bind_rows(top_models)

# Prepare the results from selected top models for the table
tidy_fe_results <- lapply(original_results, function(x) {
  if (x$Lag != 2) return(NULL)
  if (!(paste(x$Method, x$Reward) %in%
        paste(top_models$Action, top_models$Reward))) return(NULL)
  temp <- as.data.frame(x$fecoef) %>%
    rownames_to_column(var = "Term") %>%
    mutate(across(c(Estimate, `Std. Error`, `z value`, `Pr(>|z|)`),
                  as.numeric)) %>%
    filter(Term != "(Intercept)" & Term != "week_lag")
  
  return(list(
    Model = paste(x$Method, x$Reward,"Full"),
    Data  = temp,
    BIC   = x$bic,
    N     = length(x$recoef$Teacher.User.ID)))
})
tidy_fe_results <- tidy_fe_results[!sapply(tidy_fe_results, is.null)]
tidy_fe_results_restrict <- lapply(restricted_results, function(x) {
  if (x$Lag != 2) return(NULL)
  if (!(paste(x$Method, x$Reward) %in%
        paste(top_models$Action, top_models$Reward))) return(NULL)
  temp <- as.data.frame(x$fecoef) %>%
    rownames_to_column(var = "Term") %>%
    mutate(across(c(Estimate, `Std. Error`, `z value`, `Pr(>|z|)`),
                  as.numeric)) %>%
    filter(Term != "(Intercept)" & Term != "week_lag")
  
  return(list(
    Model = paste(x$Method, x$Reward,"Restricted"),
    Data  = temp,
    BIC   = x$bic,
    N     = length(x$recoef$Teacher.User.ID)))
})
tidy_fe_results_restrict <- 
  tidy_fe_results_restrict[!sapply(tidy_fe_results_restrict, is.null)]
tidy_fe_results <- c(tidy_fe_results, tidy_fe_results_restrict)

# Combine all model summaries into one dataframe
model_summary <- do.call(rbind, lapply(tidy_fe_results, function(x) {
  x_name <- unlist(strsplit(x[[1]], " "))
  x_data <- x$Data %>%
    rename(Coefficient = Estimate,
           Std_Error = `Std. Error`) %>%
    mutate(
      Significance = case_when(
        `Pr(>|z|)` < .001 ~ "***",
        `Pr(>|z|)` < .01 ~ "**",
        `Pr(>|z|)` < .05 ~ "*",
        TRUE ~ ""),
      Term = gsub(x_name[1], "lag", Term),
      Term = gsub(x_name[2], "rwd", Term),
      Term = gsub("_", "",  Term),
      Term = gsub(":", "_",  Term)) %>%
    add_row(Term = "BIC", Coefficient = x[[3]]) %>%
    add_row(Term = "N", Coefficient = x[[4]])
  x_data$Model <- x[[1]]

  x_data
})) %>% select(Model, Term, Coefficient, Std_Error, Significance) %>%
  mutate(Model = gsub(" ", "&", Model),
         Model = gsub("Frobenius.NNDSVD_student1", "Completion", Model),
         Model = gsub("Frobenius.NNDSVD_student2", "Struggle", Model),
         Model = gsub("Frobenius.NNDSVD_student3", "No. Students", Model),
         Model = gsub("Frobenius.NNDSVD_student4", "No. Sessions", Model),
         Model = gsub("Frobenius.NNDSVD_teacher1", "Assessments", Model),
         Model = gsub("Frobenius.NNDSVD_teacher2", "Scaffolding", Model),
         Model = gsub("Frobenius.NNDSVD_teacher3", "Activities", Model),
         Model = gsub("Frobenius.NNDSVD_teacher4", "Planning Guides", Model))

# Create the table using the 'gt' package
gt_table <- model_summary %>%
  filter(!Term %in% c("rwd1","rwd2","lag1","lag2")) %>%
  mutate(Estimate = ifelse(Term %in% c("BIC", "N"),
                           sprintf("%d", as.integer(Coefficient)),
                           sprintf("%1.3f%s\n(%1.3f)",
                                   Coefficient, Significance, Std_Error)),
         Term = factor(Term, levels = c("rwd1_lag1", "rwd1_lag2", "lag2_rwd2",
                                        # "lag1", "lag2",
                                        "st", "lag1_st",
                                        "BIC", "N"),
                       labels = c("R(t-1) x \n A(t-1)",
                                  "R(t-1) x \n A(t-2)",
                                  "R(t-2) x \n A(t-2)",
                                  # "Action(t-1)", "Action(t-2)",
                                  "S(t)", "S(t) x \n A(t-1)",
                                  "BIC", "N"))) %>%
  select(-Coefficient, -Std_Error, -Significance) %>%
  # Pivot wider to have one column per model
  pivot_wider(names_from = Model,
              values_from = Estimate,
              names_sep = "_") %>%
  select(order(names(.))) %>%
  arrange(Term) %>%
  gt(rowname_col = "Term") %>%
  sub_missing() %>%
  tab_spanner_delim("&") %>%
  tab_header(
    title = "Fixed Effects Logistic Regression Results"
  )

# Print the table
gt_table

```

```{r panel-model-states-restricted}
#| eval: false

#-------------
lags <- 2
n_comp = 4
n_lags = max(lags)
# Use map to iterate over methods, paste0 to concatenate strings
action <- c("Frobenius.NNDSVD_teacher")
reward <- c("Frobenius.NNDSVD_student")
# Estimation
params <- crossing(
  act = colnames(df)[str_detect(colnames(df), paste0(action, collapse = "|"))],
  lag = lags,
  st  = colnames(df)[str_detect(colnames(df), paste0(reward, collapse = "|"))],
  rwd = colnames(df)[str_detect(colnames(df), paste0(reward, collapse = "|"))]
) %>%
  filter(rwd != st) %>%
  unique()

# Data and Variables
df_bin <- as.data.table(
  df %>%
    mutate(across(dplyr::starts_with(action),
                  ~ if_else( . > median(., na.rm = TRUE), 1, 0))) %>%
    arrange(Classroom.ID, week) %>%
    # Filter out Classroom.IDs where any relevant variable has sd = 0
    group_by(Classroom.ID) %>%
    filter(Teacher.User.ID %in% teachers) %>%
    ungroup()
)

# Create lags
for (col in c(action, reward)) {
  for (lag_period in 1:n_lags) {
    df_bin <- get_lag_value(df_bin, col, lag_period, n_comp)
  }
}

# Panel data
train_data <- as.data.frame(df_bin[set == "train"])
test_data <- as.data.frame(df_bin[set == "test"])

# Estimation
# Clean environment
rm(list = setdiff(ls(), c("df", "params", "train_data", "test_data", "teachers",
                          "bic_plm", "compute_nloglik","create_formula",
                          "create_model", "get_lag_value", "model_selection")))
gc(verbose = FALSE)

cl <- makeCluster(detectCores()-1)
registerDoParallel(cl)
results <- foreach(i = 1:nrow(params),
                   .multicombine = TRUE,
                   .errorhandling = "remove",
                   .noexport = c("formula", "model",
                                 "residuals", "predictions"),
                   .packages = c("fixest", "pROC")) %dopar% {
                     act <- as.character(params$act[i])
                     lag <- params$lag[i]
                     st <- as.character(params$st[i])
                     rwd <- as.character(params$rwd[i])
                     fmla <- create_formula(action = act, reward = rwd,
                                            state = st)
                     model <- create_model(as.formula(fmla), train_data)

                     # Out of Sample Log Likelihood
                     predictions <- predict(model, newdata = test_data)

                     # Return the results as a list
                     list(Method = act,
                          Lag = lag,
                          State = st,
                          Reward = rwd,
                          formula = fmla,
                          AUC = as.numeric(
                            roc(response = test_data[,act],
                                predictor = predictions)$auc
                          ),
                          bic = BIC(model),
                          fecoef = summary(model)$coeftable,
                          recoef = fixef(model))
                   }
# Stop the cluster
stopCluster(cl)
rm(cl)

save(results, file = "fe-state-restricted-results.RData")

```

```{r}
#| label: tbl-fe-results
#| tbl-cap: "State-Based Panel Logistic Regression Results"

load("fe-state-subset-results.RData")

# Combine the model stats from original and restricted results for comparison
results_df <- do.call(rbind, lapply(results, function(x) {
  if (x$Lag != 2) return(NULL)
  data.frame(
    Action = x$Method,
    Reward = x$Reward,
    State = x$State,
    AUC = x$AUC,
    BIC = x$bic,
    Type = "Original"
  )
}))
# Select top 2 AUC models and top 2 BIC models for both original and restricted
top_models <- results_df %>%
  arrange(desc(AUC)) %>%
  slice_head(n = 2)
top_models <- results_df %>%
  arrange(BIC) %>%
  slice_head(n = 2) %>%
  bind_rows(top_models)

# Filter and tidy the results
tidy_fe_results <- lapply(results, function(x) {
  if (x$Lag != 2) return(NULL)
  if (top_models %>%
      filter(Action == x$Method &
             Reward == x$Reward &
             State  == x$State) %>%
      nrow() == 0) return(NULL)
  temp <- x$fecoef %>%
    as.data.frame() %>%
    rownames_to_column(var = "Term") %>%
    mutate(across(c(Estimate, `Std. Error`, `z value`, `Pr(>|z|)`),
                  ~ as.numeric(.))) %>%
    filter(Term != "(Intercept)" & Term != "week_lag")
  
  return(list(
    Model = paste(x$Method, x$Reward, x$State),
    Data  = temp,
    BIC   = x$bic,
    N     = length(x$recoef$Teacher.User.ID)))
})
tidy_fe_results <- tidy_fe_results[!sapply(tidy_fe_results, is.null)]
	
# Combine all model summaries into one dataframe
model_summary <- do.call(rbind, lapply(tidy_fe_results, function(x) {
  x_name <- unlist(strsplit(x$Model, " "))
  x_data <- x$Data %>%
    rename(Coefficient = Estimate,
           Std_Error = `Std. Error`) %>%
    mutate(
      Significance = case_when(
        `Pr(>|z|)` < .001 ~ "***",
        `Pr(>|z|)` < .01 ~ "**",
        `Pr(>|z|)` < .05 ~ "*",
        TRUE ~ ""),
      Term = gsub(x_name[1], "lag", Term),
      Term = gsub(x_name[2], "rwd", Term),
      Term = gsub(x_name[3], "st",  Term),
      Term = gsub("_", "",  Term),
      Term = gsub(":", "_",  Term)) %>%
    add_row(Term = "BIC", Coefficient = x[[3]]) %>%
    add_row(Term = "N", Coefficient = x[[4]])
  x_data$Model <- x$Model

  x_data
})) %>% select(Model, Term, Coefficient, Std_Error, Significance) %>%
  mutate(Model = gsub(" ", "&", Model),
         Model = gsub("Frobenius.NNDSVD_student1", "Completion", Model),
         Model = gsub("Frobenius.NNDSVD_student2", "Struggle", Model),
         Model = gsub("Frobenius.NNDSVD_student3", "No. Students", Model),
         Model = gsub("Frobenius.NNDSVD_student4", "No. Sessions", Model),
         Model = gsub("Frobenius.NNDSVD_teacher1", "Assessments", Model),
         Model = gsub("Frobenius.NNDSVD_teacher2", "Scaffolding", Model),
         Model = gsub("Frobenius.NNDSVD_teacher3", "Activities", Model),
         Model = gsub("Frobenius.NNDSVD_teacher4", "Planning Guides", Model))

# Create the table using the 'gt' package
gt_table <- model_summary %>%
  filter(!Term %in% c("rwd1","rwd2","lag1","lag2")) %>%
  mutate(Estimate = ifelse(Term %in% c("BIC", "N"),
                           sprintf("%d", as.integer(Coefficient)),
                           sprintf("%1.3f%s\n(%1.3f)",
                                   Coefficient, Significance, Std_Error)),
         Term = factor(Term, levels = c("rwd1_lag1", "rwd1_lag2", "lag2_rwd2",
                                        # "lag1", "lag2",
                                        "st1", "lag2_st1",
                                         "BIC", "N"),
                       labels = c("R(t-1) x \n A(t-1)",
                                  "R(t-1) x \n A(t-2)",
                                  "R(t-2) x \n A(t-2)",
                                  # "Action(t-1)", "Action(t-2)",
                                  "S(t-1)", "S(t-1) x \n A(t-2)",
                                  "BIC", "N"))) %>%
  select(-Coefficient, -Std_Error, -Significance) %>%
  # Pivot wider to have one column per model
  pivot_wider(names_from = Model,
              values_from = Estimate,
              names_sep = "_") %>%
  select(order(names(.))) %>%
  arrange(Term) %>%
  gt(rowname_col = "Term") %>%
  sub_missing() %>%
  tab_spanner_delim("&") %>%
  tab_header(
    title = "Fixed Effects Logistic Regression Results"
    )

# Print the table
gt_table

```




### Variability Among Teachers

```{r RL-mixed-effects}
#| eval: false

library(fixest)

create_model <- function(formula, data) {
  # Fit a logistic regression model with fixed effects
  model <- feglm(formula, data = data, family = binomial, 
                 panel.id = c("Teacher.User.ID", "week"),
                 glm.iter = 50, mem.clean = TRUE)
  return(model)
}
create_formula <- function(action, reward, state = NULL, lag = 1) {
  terms <- c()

  for (i in 1:lag) {
    # Base terms for action and reward
    terms <- c(terms, paste0(reward, "_", i), paste0(action, "_", i))

    # Interaction term for reward_i * action_i with varying slopes
    terms <- c(terms, paste0(reward, "_", i, ":", action, "_", i))

    if (i != lag) {
      for (j in (i + 1):lag) {
        # Add the interaction for reward_i * action_j when i < lag with varying slopes
        terms <- c(terms, paste0(reward, "_", i, ":", action, "_", j))
      }
    }
  }

  if (is.null(state)) {
    formula_string <- paste0(action, " ~ week_lag ",
                             " | Teacher.User.ID[",
                             paste(terms, collapse = ", "),
                             "] + week")
  } else {
    formula_string <- paste0(action, " ~ week_lag ",
                             " | Teacher.User.ID[",
                             paste(terms, collapse = ", "), ", ",
                             state, "_1, ", state, "_1:", action, "_2",
                             "] + week")
  }

  return(formula_string)
}

action <- c("Frobenius.NNDSVD_teacher")
reward <- c("Frobenius.NNDSVD_student")
lags = 2
n_lags = 2
n_comp = 4
params2 <- crossing(
  act = colnames(df)[str_detect(colnames(df),
                                paste0(action, collapse = "|"))],
  lag = lags,
  st  = c(colnames(df)[str_detect(colnames(df),
                                  paste0(reward, collapse = "|"))],
          "NA"),
  rwd = colnames(df)[str_detect(colnames(df),
                                paste0(reward, collapse = "|"))]
) %>%
  filter(rwd != st) %>%
  unique()

# Data and Variables
df_bin <- as.data.table(
  df %>%
    mutate(across(dplyr::starts_with(action),
                  ~ if_else( . > median(., na.rm = TRUE), 1, 0))) %>%
    arrange(Classroom.ID, week) %>%
    ungroup()
)

# Create lags
for (col in c(action, reward)) {
  for (lag_period in 1:n_lags) {
    df_bin <- get_lag_value(df_bin, col, lag_period, n_comp)
  }
}
# Panel data
train_data <- as.data.frame(df_bin[set == "train"])
test_data <- as.data.frame(df_bin[set == "test"])

cl <- makeCluster(detectCores()-1)
registerDoParallel(cl)
results <- foreach(i = 1:nrow(params2),
                   .multicombine = TRUE,
                   .errorhandling = "remove",
                   .noexport = c("formula", "model",
                                 "residuals", "predictions"),
                   .packages = c("fixest", "pROC", "dplyr")) %dopar% {
                     act <- as.character(params2$act[i])
                     lag <- params2$lag[i]
                     st <- NULL
                     if (as.character(params2$st[i]) != "NA") {
                       st <- as.character(params2$st[i])
                     }
                     rwd <- as.character(params2$rwd[i])
                     fmla <- create_formula(action = act, reward = rwd,
                                            state = st, lag = lag)
                     model <- create_model(as.formula(fmla), train_data)

                     # Out-of-Sample Predictions
                     predictions <- predict(model, newdata = test_data)
                     perform_df <- cbind(test_data, predictions) %>%
                       filter(!is.na(predictions), !is.na(!!sym(act))) %>%
                       group_by(Teacher.User.ID) %>%
                       filter(sd(!!sym(act)) > 0, sd(predictions) > 0) %>%
                       summarise(n_test = n(),
                                 auc_out = as.numeric(
                                   roc(response = !!sym(act),
                                       predictor = predictions,
                                       quiet = TRUE)$auc)) %>%
                       # In-Sample Predictions
                       inner_join(cbind(train_data,
                                        predictions = predict(
                                          model, newdata = train_data)) %>%
                           filter(!is.na(predictions), !is.na(!!sym(act))) %>%
                           mutate(logLik_ind = if_else(!!sym(act) == 1,
                                                       log(predictions),
                                                       log(1 - predictions))) %>%
                           group_by(Teacher.User.ID) %>%
                           filter(sd(!!sym(act)) > 0, sd(predictions) > 0) %>%
                           summarise(logLik_ind = sum(logLik_ind, na.rm = TRUE),
                                     n_train = n(),
                                     auc_in = as.numeric(
                                       roc(response = !!sym(act),
                                           predictor = predictions,
                                           quiet = TRUE)$auc)),
                           by = "Teacher.User.ID")

                     # Return the results as a list
                     list(Method = act,
                          Lag = lag,
                          State = st,
                          Reward = rwd,
                          formula = fmla,
                          AUC = as.numeric(
                            roc(response = test_data[,act],
                                predictor = predictions,
                                quiet = TRUE)$auc),
                          bic = BIC(model),
                          perform_df = perform_df,
                          fecoef = summary(model)$coeftable,
                          recoef = fixef(model))
                   }
# Stop the cluster
stopCluster(cl)
rm(cl)

save(results, file = "me-results.RData")

```

```{r RL-mixed-effects-subset}
#| eval: false

library(fixest)

load("me-results.RData")
teachers <- intersect(
  Reduce(union, sapply(results, function(x) {
    x$perform_df$Teacher.User.ID
    })),
  Reduce(intersect, sapply(results, function(x) {
    names(x$recoef$Teacher.User.ID)
    }))
  )

create_model <- function(formula, data) {
  # Fit a logistic regression model with fixed effects
  model <- feglm(formula, data = data, family = binomial, 
                 panel.id = c("Teacher.User.ID", "week"),
                 glm.iter = 50, mem.clean = TRUE)
  return(model)
}
create_formula <- function(action, reward, state = NULL, lag = 1) {
  terms <- c()

  for (i in 1:lag) {
    # Base terms for action and reward
    terms <- c(terms, paste0(reward, "_", i), paste0(action, "_", i))

    # Interaction term for reward_i * action_i with varying slopes
    terms <- c(terms, paste0(reward, "_", i, ":", action, "_", i))

    if (i != lag) {
      for (j in (i + 1):lag) {
        # Add the interaction for reward_i * action_j when i < lag with varying slopes
        terms <- c(terms, paste0(reward, "_", i, ":", action, "_", j))
      }
    }
  }

  if (is.null(state)) {
    formula_string <- paste0(action, " ~ week_lag ",
                             " | Teacher.User.ID[",
                             paste(terms, collapse = ", "),
                             "] + week")
  } else {
    formula_string <- paste0(action, " ~ week_lag ",
                             " | Teacher.User.ID[",
                             paste(terms, collapse = ", "), ", ",
                             state, "_1, ", state, "_1:", action, "_2",
                             "] + week")
  }

  return(formula_string)
}

action <- c("Frobenius.NNDSVD_teacher")
reward <- c("Frobenius.NNDSVD_student")
lags = 2
n_lags = 2
n_comp = 4
params2 <- crossing(
  act = colnames(df)[str_detect(colnames(df),
                                paste0(action, collapse = "|"))],
  lag = lags,
  st  = c(colnames(df)[str_detect(colnames(df),
                                  paste0(reward, collapse = "|"))],
          "NA"),
  rwd = colnames(df)[str_detect(colnames(df),
                                paste0(reward, collapse = "|"))]
) %>%
  filter(rwd != st) %>%
  unique()

# Data and Variables
df_bin <- as.data.table(
  df %>%
    mutate(across(dplyr::starts_with(action),
                  ~ if_else( . > median(., na.rm = TRUE), 1, 0))) %>%
    arrange(Classroom.ID, week) %>%
    filter(Teacher.User.ID %in% teachers) %>%
    ungroup()
)

# Create lags
for (col in c(action, reward)) {
  for (lag_period in 1:n_lags) {
    df_bin <- get_lag_value(df_bin, col, lag_period, n_comp)
  }
}
# Panel data
train_data <- as.data.frame(df_bin[set == "train"])
test_data <- as.data.frame(df_bin[set == "test"])

cl <- makeCluster(detectCores()-1)
registerDoParallel(cl)
results <- foreach(i = 1:nrow(params2),
                   .multicombine = TRUE,
                   .errorhandling = "remove",
                   .noexport = c("formula", "model",
                                 "residuals", "predictions"),
                   .packages = c("fixest", "pROC", "dplyr")) %dopar% {
                     act <- as.character(params2$act[i])
                     lag <- params2$lag[i]
                     st <- NULL
                     if (as.character(params2$st[i]) != "NA") {
                       st <- as.character(params2$st[i])
                     }
                     rwd <- as.character(params2$rwd[i])
                     fmla <- create_formula(action = act, reward = rwd,
                                            state = st, lag = lag)
                     model <- create_model(as.formula(fmla), train_data)

                     # Out-of-Sample Predictions
                     predictions <- predict(model, newdata = test_data)
                     perform_df <- cbind(test_data, predictions) %>%
                       filter(!is.na(predictions), !is.na(!!sym(act))) %>%
                       group_by(Teacher.User.ID) %>%
                       filter(sd(!!sym(act)) > 0, sd(predictions) > 0) %>%
                       summarise(n_test = n(),
                                 auc_out = as.numeric(
                                   roc(response = !!sym(act),
                                       predictor = predictions,
                                       quiet = TRUE)$auc)) %>%
                       # In-Sample Predictions
                       inner_join(cbind(train_data,
                                        predictions = predict(
                                          model, newdata = train_data)) %>%
                           filter(!is.na(predictions), !is.na(!!sym(act))) %>%
                           mutate(logLik_ind = if_else(!!sym(act) == 1,
                                                       log(predictions),
                                                       log(1 - predictions))) %>%
                           group_by(Teacher.User.ID) %>%
                           filter(sd(!!sym(act)) > 0, sd(predictions) > 0) %>%
                           summarise(logLik_ind = sum(logLik_ind, na.rm = TRUE),
                                     n_train = n(),
                                     auc_in = as.numeric(
                                       roc(response = !!sym(act),
                                           predictor = predictions,
                                           quiet = TRUE)$auc)),
                           by = "Teacher.User.ID")

                     # Return the results as a list
                     list(Method = act,
                          Lag = lag,
                          State = st,
                          Reward = rwd,
                          formula = fmla,
                          AUC = as.numeric(
                            roc(response = test_data[,act],
                                predictor = predictions,
                                quiet = TRUE)$auc),
                          bic = BIC(model),
                          perform_df = perform_df,
                          fecoef = summary(model)$coeftable,
                          recoef = fixef(model))
                   }
# Stop the cluster
stopCluster(cl)
rm(cl)

save(results, file = "me-subset-results.RData")

```

```{r RL-mixed-effects-restricted}
#| eval: false

library(fixest)

create_model <- function(formula, data) {
  # Fit a logistic regression model with fixed effects
  model <- feglm(formula, data = data, family = binomial, 
                 panel.id = c("Teacher.User.ID", "week"),
                 glm.iter = 50, mem.clean = TRUE)
  return(model)
}
create_formula <- function(action, reward, state = NULL) {
  terms <- c()
  terms <- c(terms, paste0(reward, "_1"))
  terms <- c(terms, paste0(action, "_2"))
  terms <- c(terms, paste0(reward, "_1:", action, "_2"))
  terms <- c(terms, paste0(action, "_1"))

  if (is.null(state)) {
    formula_string <- paste0(action, " ~ week_lag ",
                             " | Teacher.User.ID[",
                             paste(terms, collapse = ", "),
                             "] + week")
  } else {
    formula_string <- paste0(action, " ~ week_lag ",
                             " | Teacher.User.ID[",
                             paste(terms, collapse = ", "), ", ",
                             state, "_1, ", state, "_1:", action, "_2",
                             "] + week")
  }

  return(formula_string)
}

action <- c("Frobenius.NNDSVD_teacher")
reward <- c("Frobenius.NNDSVD_student")
lags = 2
n_lags = 2
n_comp = 4
params2 <- crossing(
  act = colnames(df)[str_detect(colnames(df),
                                paste0(action, collapse = "|"))],
  lag = lags,
  st  = c(colnames(df)[str_detect(colnames(df),
                                  paste0(reward, collapse = "|"))],
          "NA"),
  rwd = colnames(df)[str_detect(colnames(df),
                                paste0(reward, collapse = "|"))]
) %>%
  filter(rwd != st) %>%
  unique()

# Data and Variables
df_bin <- as.data.table(
  df %>%
    mutate(across(dplyr::starts_with(action),
                  ~ if_else( . > median(., na.rm = TRUE), 1, 0))) %>%
    arrange(Classroom.ID, week) %>%
    filter(Teacher.User.ID %in% teachers) %>%
    ungroup()
)

# Create lags
for (col in c(action, reward)) {
  for (lag_period in 1:n_lags) {
    df_bin <- get_lag_value(df_bin, col, lag_period, n_comp)
  }
}
# Panel data
train_data <- as.data.frame(df_bin[set == "train"])
test_data <- as.data.frame(df_bin[set == "test"])

cl <- makeCluster(detectCores()-1)
registerDoParallel(cl)
results <- foreach(i = 1:nrow(params2),
                   .multicombine = TRUE,
                   .errorhandling = "remove",
                   .noexport = c("formula", "model",
                                 "residuals", "predictions"),
                   .packages = c("fixest", "pROC", "dplyr")) %dopar% {
                     act <- as.character(params2$act[i])
                     lag <- params2$lag[i]
                     st <- NULL
                     if (as.character(params2$st[i]) != "NA") {
                       st <- as.character(params2$st[i])
                     }
                     rwd <- as.character(params2$rwd[i])
                     fmla <- create_formula(action = act, reward = rwd,
                                            state = st)
                     model <- create_model(as.formula(fmla), train_data)

                     # Out-of-Sample Predictions
                     predictions <- predict(model, newdata = test_data)
                     perform_df <- cbind(test_data, predictions) %>%
                       filter(!is.na(predictions), !is.na(!!sym(act))) %>%
                       group_by(Teacher.User.ID) %>%
                       filter(sd(!!sym(act)) > 0, sd(predictions) > 0) %>%
                       summarise(n_test = n(),
                                 auc_out = as.numeric(
                                   roc(response = !!sym(act),
                                       predictor = predictions,
                                       quiet = TRUE)$auc)) %>%
                       # In-Sample Predictions
                       inner_join(cbind(train_data,
                                        predictions = predict(
                                          model, newdata = train_data)) %>%
                           filter(!is.na(predictions), !is.na(!!sym(act))) %>%
                           mutate(logLik_ind = if_else(!!sym(act) == 1,
                                                       log(predictions),
                                                       log(1 - predictions))) %>%
                           group_by(Teacher.User.ID) %>%
                           filter(sd(!!sym(act)) > 0, sd(predictions) > 0) %>%
                           summarise(logLik_ind = sum(logLik_ind, na.rm = TRUE),
                                     n_train = n(),
                                     auc_in = as.numeric(
                                       roc(response = !!sym(act),
                                           predictor = predictions,
                                           quiet = TRUE)$auc)),
                           by = "Teacher.User.ID")

                     # Return the results as a list
                     list(Method = act,
                          Lag = lag,
                          State = st,
                          Reward = rwd,
                          formula = fmla,
                          AUC = as.numeric(
                            roc(response = test_data[,act],
                                predictor = predictions,
                                quiet = TRUE)$auc),
                          bic = BIC(model),
                          perform_df = perform_df,
                          fecoef = summary(model)$coeftable,
                          recoef = fixef(model))
                   }
# Stop the cluster
stopCluster(cl)
rm(cl)

save(results, file = "me-results-restricted.RData")

```


With a two-week lag established as optimal, we explored variability in model performance across teachers through a varying coefficients approach, which allows for individual slope estimations for each teacher. @tbl-RL-exploration shows pronounced variability, suggesting idiosyncratic pedagogical differences across teachers or diverse strategies tailored to classroom-specific needs. This finding highlights the need for hybrid models to accommodate teachers' diverse pedagogical approaches, strategies, and reinforcement patterns.

```{r table-RL-exploration}

library(gtExtras)
load("me-subset-results.RData")
# load("me-results-restricted.RData")

top_fits_df <- do.call(rbind, lapply(results, function(x) {
  # Assuming 'perform_df' is correctly structured as shown in your summary
  top_fits <- x$perform_df %>%
    mutate(keep = case_when(!in_hdr(n_train) ~ F,
                            !in_hdr(n_test) ~ F,
                            !in_hdr(logLik_ind) ~ F,
                            auc_in < 0.5 ~ F,
                            auc_out < 0.5 ~ F,
                            auc_in  == 1 ~ F,
                            auc_out == 1 ~ F,
                            .default = T)) %>%
    filter(keep) %>%
    summarize(
      # across(c(auc_out, auc_in, logLik_ind),
      #        ~ sd(., na.rm = T)/sqrt(n()), .names = "{.col}_se"),
      across(c(auc_out, auc_in, logLik_ind),
             ~ list(mean(., na.rm = T))),
      total = n())
  # top_fits$AUC <- x$AUC
  # top_fits$BIC <- x$bic
  top_fits$Action <- x$Method
  top_fits$Reward <- x$Reward
  top_fits$State <- ifelse(is.null(x$State), "None", x$State)
  return(top_fits)
})) %>%
  mutate(across(c(auc_out, auc_in, logLik_ind), ~ unlist(.))) %>%
  na.omit()

top_fits_df <- top_fits_df %>%
  full_join(fe_results_df %>%
              filter(Lag == 2),
            by = c("Action" = "Method", "Reward", "State")) %>%
  mutate(across(c(Action, Reward, State),
                ~ case_when(. == "Frobenius.NNDSVD_student1" ~ "Completion",
                            . == "Frobenius.NNDSVD_student2" ~ "Struggle",
                            . == "Frobenius.NNDSVD_student3" ~ "No. Students",
                            . == "Frobenius.NNDSVD_student4" ~ "No. Sessions",
                            . == "Frobenius.NNDSVD_teacher1" ~ "Assessments",
                            . == "Frobenius.NNDSVD_teacher2" ~ "Scaffolding",
                            . == "Frobenius.NNDSVD_teacher3" ~ "Activities",
                            . == "Frobenius.NNDSVD_teacher4" ~ "Planning Guides",
                            .default = .)))
  
top_statefree <- rbind(
  top_fits_df %>% filter(State == "None") %>%
    arrange(desc(auc)) %>% slice_head(n = 1) %>% select(Action, Reward),
  top_fits_df %>% filter(State == "None") %>%
    arrange(bic) %>% slice_head(n = 1) %>% select(Action, Reward),
  top_fits_df %>% filter(State == "None") %>%
    arrange(desc(auc_out)) %>% slice_head(n = 1) %>% select(Action, Reward),
  top_fits_df %>% filter(State == "None") %>%
    arrange(desc(logLik_ind)) %>% slice_head(n = 1) %>% select(Action, Reward)
)
top_statebased <- rbind(
  top_fits_df %>% filter(State != "None") %>%
    arrange(desc(auc)) %>% slice_head(n = 1) %>% select(Action, Reward, State),
  top_fits_df %>% filter(State != "None") %>%
    arrange(bic) %>% slice_head(n = 1) %>% select(Action, Reward, State),
  top_fits_df %>% filter(State != "None") %>%
    arrange(desc(auc_out)) %>% slice_head(n = 1) %>% select(Action, Reward, State),
  top_fits_df %>% filter(State != "None") %>%
    arrange(desc(logLik_ind)) %>% slice_head(n = 1) %>% select(Action, Reward, State)
)

top_fits_df %>%
  mutate(bic = bic/1000) %>%
  select(auc, bic, auc_out, logLik_ind) %>%
  rename("FE AUC" = auc,
         "FE BIC (x10<sup>3</sup>)" = bic,
         "Avg. Hiearchical AUC" = auc_out,
         "Avg. Hiearchical Log Likelihood" = logLik_ind) %>%
  gt_plt_summary(title = "Model Performance") %>%
  fmt_markdown() %>%
  # Remove "Missing" column
  cols_hide(n_missing) %>%
  fmt_number(
    columns = c(Mean, Median, SD),
    decimals = 2
  ) %>%
  # Add columns for top models
  cols_add(
    top_action = top_statefree$Action,
    top_reward = top_statefree$Reward,
    top_action_st = top_statebased$Action,
    top_reward_st = top_statebased$Reward,
    top_state = top_statebased$State) %>%
  cols_label(
    top_action = "Top Action",
    top_reward = "Top Reward",
    top_action_st = "Top Action",
    top_reward_st = "Top Reward",
    top_state = "Top State"
  ) %>%
  tab_spanner(
    label = "State-Free",
    columns = c(top_action, top_reward)
  ) %>%
  tab_spanner(
    label = "State-Based",
    columns = c(top_action_st, top_reward_st, top_state)
  ) %>% gt::gtsave(filename = "tbl-RL-exploration.png")

```

![](tbl-RL-exploration.png){#tbl-RL-exploration}

### Model Selection and Interpretability

#### Model Selection Part 1

We then refined our analysis to highlight models that demonstrated robustness and high predictive accuracy and provided meaningful insights into the interactions between rewards, actions, and states.

@fig-RL-exploration showcases 11 models selected with the highest a) fixed effects AUC, b) mean teacher-specific AUC, c) lowest fixed effects BIC, and d) highest mean teacher-specific log-likelihood, with the top state-free model of each category selected along with the top two state-based models from each category. Models closest to the bottom right corner of the graph (lowest BIC, highest out-of-sample AUC) do best in balancing parsimony in the fixed effects model and predictability in the varying coefficients model. In general, @fig-RL-exploration suggests that the best-fitting models use scaffolding as their action, but the best rewards and states are not clearly defined.

```{r}
#| label: fig-RL-exploration
#| fig-cap: "Top AUC x BIC Models"
#| fig-subcap: 
#|   - "State-free"
#|   - "State-dependent"
#| layout-ncol: 2

# Select top models by BIC (lower is better) and AUC (higher is better)

# Keep models for later analysis
selected_models <- top_fits_df %>%
  filter(State == "None") %>%
  filter(auc_out > 0.7, bic < 90000)

## State-free
plot1 <- top_fits_df %>%
  filter(State == "None") %>%
  select(Action, Reward, bic, auc_out) %>%
  ggplot(aes(x = bic, y = auc_out, color = Reward)) +
  geom_point() +
  theme(legend.position = "bottom") +
  geom_mark_ellipse(
    aes(group = Action, label = Action, color = NULL),
    con.type = "straight",
    con.cap = 0,
    expand = .02,
    label.buffer = unit(0.1, "mm")
  ) +
  # Draw a segment for the x-line up to y = 90000
  geom_segment(x = 84000, y = 0.7, xend = 90000, yend = 0.7,
               linetype = "dashed", color = "darkgray") +
  # Draw a segment for the y-line starting from x = 0.7
  geom_segment(x = 90000, y = 0.7, xend = 90000, yend = 0.72,
               linetype = "dashed", color = "darkgray") +
  theme_minimal() +
  labs(x = "BIC F.E.", y = "Avg. AUC M.E.",
       title = paste(nrow(selected_models), "Models Selected"))

# Join with selected_models
selected_models <- bind_rows(
  selected_models,
  top_fits_df %>%
    filter(State != "None") %>%
    filter(auc_out > 0.7, bic < 90000)
  )

## State-based
plot2 <- top_fits_df %>%
  filter(State != "None") %>%
  select(Action, Reward, State, bic, auc_out) %>%
  ggplot(aes(x = bic, y = auc_out, color = Reward, shape = State)) +
  geom_point() +
  theme(legend.position = "bottom") +
  geom_mark_ellipse(
    aes(group = Action, label = Action, color = NULL),
    con.type = "straight",
    con.cap = 0,
    expand = .02,
    label.buffer = unit(0.1, "mm")
  ) +
  # Draw a segment for the x-line up to y = 90000
  geom_segment(x = 84000, y = 0.7, xend = 90000, yend = 0.7,
               linetype = "dashed", color = "darkgray") +
  # Draw a segment for the y-line starting from x = 0.7
  geom_segment(x = 90000, y = 0.7, xend = 90000, yend = 0.72,
               linetype = "dashed", color = "darkgray") +
  theme_minimal() +
  labs(x = "BIC F.E.", y = "Avg. AUC M.E.",
       title = paste(nrow(selected_models %>% filter(State != "None")),
                     "Models Selected"))

plot1
plot2

```

```{r RL-me-interpretation}
#| eval: false

library(fixest)

create_model <- function(formula, data) {
  # Fit a logistic regression model with fixed effects
  model <- feglm(formula, data = data, family = binomial, 
                 panel.id = c("Teacher.User.ID", "week"),
                 glm.iter = 50, mem.clean = TRUE)
  return(model)
}

# Use only reward_1:action_2 given the previous results
create_formula <- function(action, reward, state = NULL) {
  terms <- c()
  
  # Interaction term for reward_i * action_i
  terms <- c(terms, paste0(reward, "_1"))
  terms <- c(terms, paste0(action, "_1"))
  terms <- c(terms, paste0(reward, "_1:", action, "_1"))
  
  terms <- c(terms, paste0(reward, "_1:", action, "_2"))
  terms <- c(terms, paste0(reward, "_2"))
  terms <- c(terms, paste0(action, "_2"))
  terms <- c(terms, paste0(reward, "_2:", action, "_2"))

  if (is.null(state)) {
    formula_string <- paste0(action, " ~ week_lag ",
                             " | Teacher.User.ID[",
                             paste(terms, collapse = ", "),
                             "] + week")
  } else {
    formula_string <- paste0(action, " ~ week_lag ",
                             " | Teacher.User.ID[",
                             paste(terms, collapse = ", "), ", ",
                             state, "_1, ", state, "_1:", action, "_2",
                             "] + week")
  }

  return(formula_string)
}

action <- c("Frobenius.NNDSVD_teacher")
reward <- c("Frobenius.NNDSVD_student")
lags = 2
n_lags = 2
n_comp = 4
params2 <- crossing(
  act = colnames(df)[str_detect(colnames(df),
                                paste0(action, collapse = "|"))],
  lag = lags,
  st  = c(colnames(df)[str_detect(colnames(df),
                                  paste0(reward, collapse = "|"))],
          "NA"),
  rwd = colnames(df)[str_detect(colnames(df),
                                paste0(reward, collapse = "|"))]
) %>%
  filter(rwd != st) %>%
  unique() %>%
  semi_join(
    selected_models %>%
      select(Action, Reward, State) %>%
      mutate(across(c(Action, Reward, State),
                    ~ case_when(. == "Completion" ~ "Frobenius.NNDSVD_student1",
                                . == "Struggle" ~ "Frobenius.NNDSVD_student2",
                                . == "No. Students" ~ "Frobenius.NNDSVD_student3",
                                . == "No. Sessions" ~ "Frobenius.NNDSVD_student4",
                                . == "Assessments" ~ "Frobenius.NNDSVD_teacher1",
                                . == "Scaffolding" ~ "Frobenius.NNDSVD_teacher2",
                                . == "Activities" ~ "Frobenius.NNDSVD_teacher3",
                                . == "Planning Guides" ~ "Frobenius.NNDSVD_teacher4",
                                . == "None" ~ "NA",
                                .default = .))),
    by = c("act" = "Action", "rwd" = "Reward", "st" = "State"))

# Data and Variables
df_bin <- as.data.table(
  df %>%
    mutate(across(dplyr::starts_with(action),
                  ~ if_else( . > median(., na.rm = TRUE), 1, 0))) %>%
    mutate(across(dplyr::starts_with(reward), ~ ./sd(., na.rm = TRUE))) %>%
    arrange(Classroom.ID, week) %>%
    filter(Teacher.User.ID %in% teachers) %>%
    ungroup()
)

# Create lags
for (col in c(action, reward)) {
  for (lag_period in 1:n_lags) {
    df_bin <- get_lag_value(df_bin, col, lag_period, n_comp)
  }
}
# Panel data
train_data <- as.data.frame(df_bin[set == "train"])
test_data <- as.data.frame(df_bin[set == "test"])

cl <- makeCluster(min(nrow(params2), detectCores()-1))
registerDoParallel(cl)
results <- foreach(i = 1:nrow(params2),
                   .multicombine = TRUE,
                   .errorhandling = "remove",
                   .noexport = c("formula", "model",
                                 "residuals", "predictions"),
                   .packages = c("fixest", "pROC", "dplyr")) %dopar% {
                     act <- as.character(params2$act[i])
                     lag <- params2$lag[i]
                     st <- NULL
                     if (as.character(params2$st[i]) != "NA") {
                       st <- as.character(params2$st[i])
                     }
                     rwd <- as.character(params2$rwd[i])
                     fmla <- create_formula(action = act, reward = rwd,
                                            state = st)
                     model <- create_model(as.formula(fmla), train_data)

                     # Out-of-Sample Predictions
                     predictions <- predict(model, newdata = test_data)
                     perform_df <- cbind(test_data, predictions) %>%
                       filter(!is.na(predictions), !is.na(!!sym(act))) %>%
                       group_by(Teacher.User.ID) %>%
                       filter(sd(!!sym(act)) > 0, sd(predictions) > 0) %>%
                       summarise(n_test = n(),
                                 auc_out = as.numeric(
                                   roc(response = !!sym(act),
                                       predictor = predictions,
                                       quiet = TRUE)$auc)) %>%
                       # In-Sample Predictions
                       inner_join(cbind(train_data,
                                        predictions = predict(
                                          model, newdata = train_data)) %>%
                           filter(!is.na(predictions), !is.na(!!sym(act))) %>%
                           mutate(logLik_ind = if_else(!!sym(act) == 1,
                                                       log(predictions),
                                                       log(1 - predictions))) %>%
                           group_by(Teacher.User.ID) %>%
                           filter(sd(!!sym(act)) > 0, sd(predictions) > 0) %>%
                           summarise(logLik_ind = sum(logLik_ind, na.rm = TRUE),
                                     n_train = n(),
                                     auc_in = as.numeric(
                                       roc(response = !!sym(act),
                                           predictor = predictions,
                                           quiet = TRUE)$auc)),
                           by = "Teacher.User.ID")

                     # Return the results as a list
                     list(Method = act,
                          Lag = lag,
                          State = st,
                          Reward = rwd,
                          formula = fmla,
                          AUC = as.numeric(
                            roc(response = test_data[,act],
                                predictor = predictions,
                                quiet = TRUE)$auc),
                          bic = BIC(model),
                          perform_df = perform_df,
                          fecoef = summary(model)$coeftable,
                          recoef = fixef(model))
                   }
# Stop the cluster
stopCluster(cl)
rm(cl)

save(results, file = "me-standardized-coef.RData")

```

#### Model Selection Part 2

We applied further scrutiny to the top models through re-estimation with scaled independent variables, enabling a direct comparison of coefficients. In this case, an increase of 1 unit in the independent variable represents an increase of one standard deviation. @tbl-re-estimation summarizes these results, revealing the standardized coefficients for reward and state variables and their interactions with lagged actions.

Here, we sought the models with coefficients presenting attributes most resembling RL. Specifically, the interaction between rewards and actions positively influenced future actions for desired outcomes (e.g., lesson completion) and negatively for undesired outcomes (e.g., struggles). Further, state-based models should incorporate the effects of current states on strategic action selection. The interaction term between states and lagged actions further points to the role of actions in achieving and maintaining desired states.

Notably, the models underscore the absence of a one-size-fits-all approach, indicating a spectrum of strategies where some teachers' practices align more closely with RL principles than others. Ranking the models by the proportion of teachers whose coefficients present RL-like effects, this analysis favors 1) Action: Scaffolding, Reward: No. Sessions, State: No. Students; 2) Action: Activities, Reward: Completion, State: No. Students; and 3) Action: Assessments, Reward: No. Students, State: Completion. @fig-RL-exploration, on the other hand, highlights the models closest to the bottom right corner: 1) Action: Scaffolding, Reward: No. Students, State: No. Sessions; 2) Action: Scaffolding, Reward: No. Sessions, State-free; 3) Action: Scaffolding, Reward: No. Sessions, State: Completion; 4) Action: Activities, Reward: Completion, State: No. Students; and 5) Action: Activities, Reward: Struggle, State-free. Overall, the complexity of these individual differences and the model performance calls for hybrid modeling in future RL-fitting steps.

```{=tex}
\newpage
\KOMAoptions{paper=landscape,pagesize}
\recalctypearea
{\areaset[current]{\dimexpr\textwidth\relax}{\textheight}
\setlength{\marginparwidth}{0pt}
\scriptsize
```

```{r}
#| label: tbl-re-estimation-statefree
#| tbl-cap: "State-Free Mixed Effects Logistic Regression Results"

load("me-standardized-coef.RData")

filtered_results <- lapply(results, function(x) {
  if (!is.null(x$State)) return(NULL)
  temp <- data.frame(
    Action = x$Method,
    Reward = x$Reward,
    State = "None"
  ) %>%
  mutate(across(c(Action, Reward),
                ~ case_when(. == "Frobenius.NNDSVD_student1" ~ "Completion",
                            . == "Frobenius.NNDSVD_student2" ~ "Struggle",
                            . == "Frobenius.NNDSVD_student3" ~ "No. Students",
                            . == "Frobenius.NNDSVD_student4" ~ "No. Sessions",
                            . == "Frobenius.NNDSVD_teacher1" ~ "Assessments",
                            . == "Frobenius.NNDSVD_teacher2" ~ "Scaffolding",
                            . == "Frobenius.NNDSVD_teacher3" ~ "Activities",
                            . == "Frobenius.NNDSVD_teacher4" ~ "Planning Guides",
                            .default = .)))
  if(nrow(
    temp %>%
    semi_join(selected_models, by = c("Action", "Reward", "State"))
    ) == 0) return(NULL)
  if(x$AUC < 0.5) return(NULL)
  x$recoef <- do.call(cbind, x$recoef[-c(1, length(x$recoef))]) %>%
    as.data.frame() %>%
    filter(if_all(everything(),
                  ~ . >= find_hdr(.)[1] & . <= find_hdr(.)[2])) %>%
    rownames_to_column(var = "Teacher.User.ID")
  
  return(list(
    Action = temp$Action,
    Reward = temp$Reward,
    AUCmodel = x$AUC,
    BICmodel = x$bic,
    coef = data.frame(
      Teacher.User.ID = as.integer(x$recoef[,1]),
      lag1 = x$recoef[,3],
      lag2 = x$recoef[,7],
      rwd1 = x$recoef[,2],
      rwd2 = x$recoef[,6],
      rwd1_lag1 = x$recoef[,4],
      rwd1_lag2 = x$recoef[,5],
      rwd2_lag2 = x$recoef[,8]
    ) %>%
      inner_join(x$perform_df %>%
                   select(Teacher.User.ID, auc_out, logLik_ind) %>%
                   filter(if_all(everything(), ~ . >= find_hdr(.)[1] &
                                                 . <= find_hdr(.)[2])) %>%
                   filter(0.5 < auc_out & auc_out < 1),
                 by = "Teacher.User.ID")
  ))
})
filtered_results <- filtered_results[!sapply(filtered_results, is.null)]

model_summary <- do.call(rbind, lapply(filtered_results, function(x) {
  summary <- data.frame(
    Action = x$Action,
    Reward = x$Reward,
    AUC = x$AUCmodel,
    BIC = x$BICmodel
  )
  summary$lag1 = list(x$coef$lag1)
  summary$lag2 = list(x$coef$lag2)
  summary$rwd1_lag1 = list(x$coef$rwd1_lag1)
  summary$rwd1_lag2 = list(x$coef$rwd1_lag2)
  summary$rwd2_lag2 = list(x$coef$rwd2_lag2)
  summary$auc_ind = list(x$coef$auc_out)
  summary$logLik_ind = list(x$coef$logLik_ind)
  
  summary <- summary %>%
    # # Standardize the coefficients by dividing by the standard deviation
    # mutate(across(c(rwd1_lag1, rwd1_lag2, rwd2_lag2, st, st_lag1),
    #               ~ lapply(., function(x) x / sd(x, na.rm = T)))) %>%
    # # Fill in x$State == "None" with 0s
    # mutate(across(c(st, st_lag1), ~ if_else(is.na(.), list(0), .))) %>%
    mutate(n_teachers = lapply(summary$lag1, length)) %>%
    mutate(across(c(lag1, lag2,
                    rwd1_lag1,
                    rwd1_lag2, 
                    rwd2_lag2,
                    auc_ind, logLik_ind),
                  ~ lapply(., mean, na.rm = T),
                  .names = "{.col}.mean")) %>%
    mutate(across(c(lag1, lag2,
                    rwd1_lag1,
                    rwd1_lag2,
                    rwd2_lag2
                    ),
                  ~ lapply(., sd, na.rm = T),
                  .names = "{.col}.sd")) %>%
    mutate(across(c(lag1, lag2,
                    rwd1_lag1,
                    rwd1_lag2,
                    rwd2_lag2
                    ),
                  ~ lapply(., quantile, 0.25, names = F),
                  .names = "{.col}.q1")) %>%
    mutate(across(c(lag1, lag2,
                    rwd1_lag1,
                    rwd1_lag2,
                    rwd2_lag2
                    ),
                  ~ lapply(., median, na.rm = T),
                  .names = "{.col}.median")) %>%
    mutate(across(c(lag1, lag2,
                    rwd1_lag1,
                    rwd1_lag2,
                    rwd2_lag2
                    ),
                  ~ lapply(., quantile, 0.75, names = F),
                  .names = "{.col}.q3")) %>%
    mutate(across(c(lag1, lag2,
                    rwd1_lag1,
                    rwd1_lag2,
                    rwd2_lag2
                    ),
                  ~ lapply(., function(x) mean(x > 0, na.rm = T)),
                  .names = "{.col}.pos")) %>%
    select(-c(lag1, lag2,
              rwd1_lag1,
              rwd1_lag2,
              rwd2_lag2,
              auc_ind, logLik_ind, auc_ind.mean, logLik_ind.mean))
  
  return(summary)
}))

# Transform the model_summary dataframe to a long format for plotting
model_summary_long <- model_summary %>%
  mutate(across(!c(Action, Reward), as.numeric)) %>%
  mutate(across(dplyr::ends_with(".pos") & dplyr::starts_with("rwd"),
                ~ case_when(Reward == "Struggle" ~ 1 - ., .default = .))) %>%
  select(!c(AUC, BIC)) %>%
  pivot_longer(cols = -c(Action, Reward), 
               names_to = c("variable", "statistic"), values_to = "value",
               names_sep = "\\.") %>%
  arrange(Action, Reward) %>%
  pivot_wider(names_from = c(Action, Reward), values_from = c(value))
  
max <- model_summary_long %>%
  filter(statistic == "pos" & !variable %in% c("lag1","lag2")) %>%
  rowwise() %>%
  # Remove columns that do not have the max of at least 1 row
  mutate(max_val = max(c_across(is.numeric), na.rm = T)) %>%
  ungroup() %>%
  mutate(across(is.numeric, ~ if_else(. == max_val, ., NA))) %>%
  select(where(~ !all(is.na(.)))) %>%
  select(-c("max_val","statistic")) %>%
  mutate(across(is.numeric, ~ !is.na(.))) %>%
  pivot_longer(cols = -variable, names_to = "model", values_to = "keep") %>%
  filter(keep) %>% select(-keep)

model_summary_long %>%
  filter(!variable %in% c("lag1", "lag2")) %>%
  mutate(statistic = factor(statistic,
                            levels = c("mean", "sd", "q1", "median", "q3", "pos"),
                            labels = c("Mean", "SD", "Q1", "Median", "Q3", "RL-like")),
         variable = factor(variable,
                           levels = c(
                             # "lag1", "lag2",
                             "rwd1_lag1",
                             "rwd1_lag2",
                             "rwd2_lag2",
                             "n_teachers"),
                           labels = c(
                             # "Action(t-1)",
                             # "Action(t-2)",
                             "R(t-1) x \n A(t-1)",
                             "R(t-1) x \n A(t-2)",
                             "R(t-2) x \n A(t-2)",
                             "N"
                             ))) %>%
  select(order(names(model_summary_long))) %>%
  group_by(variable) %>%
  gt(rowname_col = "statistic", row_group_as_column = T) %>%
  row_group_order(groups = c(
    # "Action(t-1)",
    # "Action(t-2)",
    "R(t-1) x \n A(t-1)",
    "R(t-1) x \n A(t-2)",
    "R(t-2) x \n A(t-2)",
    "N")) %>%
  fmt_markdown(columns = "variable") %>%
  fmt_number(decimals = 2) %>%
  fmt_integer(rows = variable == "No. Teachers") %>%
  fmt_percent(rows = statistic == "RL-like") %>%
  # cols_hide(starts_with("Assessments_No. Students")) %>%
  sub_missing() %>%
  tab_spanner_delim("_") %>%
  tab_header(
    title = "Summary of Model Coefficients"
  ) %>%
  tab_options(
    table.font.size = "small"
  )
  # as_latex()

```

```{=tex}
\newpage
```

```{r}
#| label: tbl-re-estimation
#| tbl-cap: "State-Based Mixed Effects Logistic Regression Results"

load("me-standardized-coef.RData")

filtered_results <- lapply(results, function(x) {
  if (is.null(x$State)) return(NULL)
  temp <- data.frame(
    Action = x$Method,
    Reward = x$Reward,
    State = x$State
  ) %>%
  mutate(across(c(Action, Reward, State),
                ~ case_when(. == "Frobenius.NNDSVD_student1" ~ "Completion",
                            . == "Frobenius.NNDSVD_student2" ~ "Struggle",
                            . == "Frobenius.NNDSVD_student3" ~ "No. Students",
                            . == "Frobenius.NNDSVD_student4" ~ "No. Sessions",
                            . == "Frobenius.NNDSVD_teacher1" ~ "Assessments",
                            . == "Frobenius.NNDSVD_teacher2" ~ "Scaffolding",
                            . == "Frobenius.NNDSVD_teacher3" ~ "Activities",
                            . == "Frobenius.NNDSVD_teacher4" ~ "Planning Guides",
                            .default = .)))
  if(nrow(
    temp %>%
    semi_join(selected_models, by = c("Action", "Reward", "State"))
    ) == 0) return(NULL)
  if(x$AUC < 0.5) return(NULL)
  x$recoef <- do.call(cbind, x$recoef[-c(1, length(x$recoef))]) %>%
    as.data.frame() %>%
    filter(if_all(everything(),
                  ~ . >= find_hdr(.)[1] & . <= find_hdr(.)[2])) %>%
    rownames_to_column(var = "Teacher.User.ID")
  
  return(list(
    Action = temp$Action,
    Reward = temp$Reward,
    State = temp$State,
    AUCmodel = x$AUC,
    BICmodel = x$bic,
    coef = data.frame(
      Teacher.User.ID = as.integer(x$recoef[,1]),
      lag1 = x$recoef[,3],
      lag2 = x$recoef[,7],
      rwd1 = x$recoef[,2],
      rwd2 = x$recoef[,6],
      rwd1_lag1 = x$recoef[,4],
      rwd1_lag2 = x$recoef[,5],
      rwd2_lag2 = x$recoef[,8],
      st = x$recoef[,9],
      st_lag1 = x$recoef[,10]
    ) %>%
      inner_join(x$perform_df %>%
                   select(Teacher.User.ID, auc_out, logLik_ind) %>%
                   filter(auc_out >= 0.5 & auc_out < 1),
                 by = "Teacher.User.ID")
  ))
  })
filtered_results <- filtered_results[!sapply(filtered_results, is.null)]

model_summary <- do.call(rbind, lapply(filtered_results, function(x) {
  summary <- data.frame(
    Action = x$Action,
    Reward = x$Reward,
    State = x$State,
    AUC = x$AUCmodel,
    BIC = x$BICmodel
  )
  summary$lag1 = list(x$coef$lag1)
  summary$lag2 = list(x$coef$lag2)
  summary$rwd1_lag1 = list(x$coef$rwd1_lag1)
  summary$rwd1_lag2 = list(x$coef$rwd1_lag2)
  summary$rwd2_lag2 = list(x$coef$rwd2_lag2)
  summary$st = ifelse(x$State == "None", list(0), list(x$coef$st))
  summary$st_lag1 = ifelse(x$State == "None", list(0), list(x$coef$st_lag1))
  summary$auc_ind = list(x$coef$auc_out)
  summary$logLik_ind = list(x$coef$logLik_ind)
  
  summary <- summary %>%
    # # Standardize the coefficients by dividing by the standard deviation
    # mutate(across(c(rwd1_lag1, rwd1_lag2, rwd2_lag2, st, st_lag1),
    #               ~ lapply(., function(x) x / sd(x, na.rm = T)))) %>%
    # # Fill in x$State == "None" with 0s
    # mutate(across(c(st, st_lag1), ~ if_else(is.na(.), list(0), .))) %>%
    mutate(n_teachers = lapply(summary$lag1, length)) %>%
    mutate(across(c(lag1, lag2,
                    rwd1_lag1,
                    rwd1_lag2,
                    rwd2_lag2,
                    st, st_lag1,
                    auc_ind, logLik_ind),
                  ~ lapply(., mean, na.rm = T),
                  .names = "{.col}.mean")) %>%
    mutate(across(c(lag1, lag2,
                    rwd1_lag1,
                    rwd1_lag2,
                    rwd2_lag2,
                    st, st_lag1),
                  ~ lapply(., sd, na.rm = T),
                  .names = "{.col}.sd")) %>%
    mutate(across(c(lag1, lag2,
                    rwd1_lag1,
                    rwd1_lag2,
                    rwd2_lag2,
                    st, st_lag1),
                  ~ lapply(., quantile, 0.25, names = F),
                  .names = "{.col}.q1")) %>%
    mutate(across(c(lag1, lag2,
                    rwd1_lag1,
                    rwd1_lag2,
                    rwd2_lag2,
                    st, st_lag1),
                  ~ lapply(., median, na.rm = T),
                  .names = "{.col}.median")) %>%
    mutate(across(c(lag1, lag2,
                    rwd1_lag1,
                    rwd1_lag2,
                    rwd2_lag2,
                    st, st_lag1),
                  ~ lapply(., quantile, 0.75, names = F),
                  .names = "{.col}.q3")) %>%
    mutate(across(c(lag1, lag2,
                    rwd1_lag1,
                    rwd1_lag2,
                    rwd2_lag2,
                    st, st_lag1),
                  ~ lapply(., function(x) mean(x > 0, na.rm = T)),
                  .names = "{.col}.pos")) %>%
    select(-c(lag1, lag2,
              rwd1_lag1,
              rwd1_lag2,
              rwd2_lag2,
              st, st_lag1,
              auc_ind, logLik_ind, auc_ind.mean, logLik_ind.mean))
  
  return(summary)
}))

# Transform the model_summary dataframe to a long format for plotting
model_summary_long <- model_summary %>%
  mutate(across(!c(Action, Reward, State), as.numeric)) %>%
  mutate(across(dplyr::ends_with(".pos") & dplyr::starts_with("st"),
                ~ case_when(State == "Struggle" ~ 1 - ., .default = .)),
         across(dplyr::ends_with(".pos") & dplyr::starts_with("rwd"),
                ~ case_when(Reward == "Struggle" ~ 1 - ., .default = .))) %>%
  select(!c(AUC, BIC)) %>%
  mutate(across(dplyr::starts_with("st", ignore.case = F),
                ~ if_else(State == "None", NA, .))) %>%
  pivot_longer(cols = -c(Action, Reward, State), 
               names_to = c("variable", "statistic"), values_to = "value",
               names_sep = "\\.") %>%
  arrange(Action, Reward, State) %>%
  pivot_wider(names_from = c(Action, Reward, State), values_from = c(value))
  
max <- model_summary_long %>%
  filter(statistic == "pos" & !variable %in% c("lag1","lag2")) %>%
  rowwise() %>%
  # Remove columns that do not have the max of at least 1 row
  mutate(max_val = max(c_across(is.numeric), na.rm = T)) %>%
  ungroup() %>%
  mutate(across(is.numeric, ~ if_else(. == max_val, ., NA))) %>%
  select(where(~ !all(is.na(.)))) %>%
  select(-c("max_val","statistic")) %>%
  mutate(across(is.numeric, ~ !is.na(.))) %>%
  pivot_longer(cols = -variable, names_to = "model", values_to = "keep") %>%
  filter(keep) %>% select(-keep)

model_summary_long %>%
  filter(!variable %in% c("lag1", "lag2")) %>%
  mutate(statistic = factor(statistic,
                            levels = c("mean", "sd", "q1", "median", "q3", "pos"),
                            labels = c("Mean", "SD", "Q1", "Median", "Q3", "RL-like")),
         variable = factor(variable,
                           levels = c(
                             # "lag1", "lag2",
                             "rwd1_lag1",
                             "rwd1_lag2",
                             "rwd2_lag2",
                             "st", "st_lag1",
                             "n_teachers"),
                           labels = c(
                             # "Action(t-1)",
                             # "Action(t-2)",
                             "R(t-1) x \n A(t-1)",
                             "R(t-1) x \n A(t-2)",
                             "R(t-2) x \n A(t-2)",
                             "S(t)",
                             "S(t) x \n A(t-1)",
                             "N"
                             ))) %>%
  select(order(names(model_summary_long))) %>%
  group_by(variable) %>%
  gt(rowname_col = "statistic", row_group_as_column = T) %>%
  row_group_order(groups = c(
    # "Action(t-1)",
    # "Action(t-2)",
    "R(t-1) x \n A(t-1)",
    "R(t-1) x \n A(t-2)",
    "R(t-2) x \n A(t-2)",
    "S(t)",
    "S(t) x \n A(t-1)",
    "N")) %>%
  fmt_markdown(columns = "variable") %>%
  fmt_number(decimals = 2) %>%
  fmt_integer(rows = variable == "No. Teachers") %>%
  fmt_percent(rows = statistic == "RL-like") %>%
  # cols_hide(starts_with("Assessments_No. Students")) %>%
  sub_missing() %>%
  tab_spanner_delim("_") %>%
  tab_header(
    title = "Summary of Model Coefficients"
  ) %>%
  tab_options(
    table.font.size = "small"
  )
  # as_latex()

```

```{=tex}
}
\newpage
\KOMAoptions{paper=portrait,pagesize}
\recalctypearea
```


# Methods

## Panel Model Estimation for Lag Selection

We specified and estimated panel logistic regression models to capture the dynamics of actions influenced by lagged rewards and actions, including their interactions. The general model formulation for both state-free and state-based scenarios is presented as follows:

### State-Free Model

```{=tex}
\begin{align*}
\text{Action}_t =& \ \sum_{i=1}^{L} \left( \beta_{i} \text{Reward}_{t-i} + \gamma_i \text{Action}_{t-i} + \sum_{j=i}^{L} \delta_{ij} (\text{Reward}_{t-i} \times \text{Action}_{t-j}) \right) \\
& + \mu_{\text{Teacher}} + \lambda_{\text{Week}} + \epsilon_t 
\end{align*}
```
### State-Based Model

```{=tex}
\begin{align*}
\text{Action}_t =& \ \sum_{i=1}^{L} \left( \beta_{i} \text{Reward}_{t-i} + \gamma_i \text{Action}_{t-i} + \sum_{j=i}^{L} \delta_{ij} (\text{Reward}_{t-i} \times \text{Action}_{t-j}) \right) \\
& + \phi \text{State}_t + \psi (\text{State}_t \times \text{Action}_{t-1}) + \mu_{\text{Teacher}} + \lambda_{\text{Week}} + \epsilon_t
\end{align*}
```
where $\text{Action}_t$ denotes the binary outcome at time $t$, $\text{Reward}_{t-i}$ and $\text{Action}_{t-i}$ represent the reward and action variables lagged by $i$ periods, and $L$ is the maximum lag considered. $\mu_{\text{Teacher}}$ and $\lambda_{\text{Week}}$ represent fixed effects for teachers and weeks, respectively.

Model performance was assessed using the area under the receiver operating characteristic curve (AUC) and Bayesian Information Criterion (BIC). Optimal lag structures were identified based on predictive accuracy and model parsimony.

We used a varying coefficients model to capture individual teacher effects on the dynamics between rewards, actions, and states. The model is specified as follows:

```{=tex}
\begin{align*}
\text{Action}_{kt} =& \ \sum_{i=1}^{L} \left( \beta_{ki} \text{Reward}_{k, t-i} + \gamma_{ki} \text{Action}_{k, t-i} + \sum_{j=i}^{L} \delta_{kij} (\text{Reward}_{k, t-i} \times \text{Action}_{k, t-j}) \right) \\
& + \phi_k \text{State}_{kt} + \psi_k (\text{State}_{kt} \times \text{Action}_{k, t-1}) + \mu_k + \lambda_{\text{Week}} + \epsilon_{kt}
\end{align*}
```
where $\beta_{ki}$, $\gamma_{ki}$, and $\delta_{kij}$ represent the reward, action, and their interaction coefficients that vary by teacher; $\phi_k$ and $\psi_k$ are the fixed effects for the state and the interaction between state and lagged action, respectively; and $\mu_k$ and $\lambda_{\text{Week}}$ are fixed effects for teachers and weeks, respectively.

To assess the model's predictive accuracy and generalizability, we used the out-of-sample AUC as a performance metric, calculated separately for each teacher.
