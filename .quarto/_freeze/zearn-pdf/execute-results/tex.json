{
  "hash": "1c421e9c185280449c700164f9230196",
  "result": {
    "markdown": "---\ntitle: \"Predicting Repeated Behavior in Behavioral Sciences\"\nsubtitle: \"Applying Reinforcement Learning in Teacher Decision-Making\"\nformat: pdf\n---\n\n\n## Predicting Repeated Behavior in Behavioral Sciences\n\nApplying Reinforcement Learning in Teacher Decision-Making\n\n![Teacher and Students](https://assets-global.website-files.com/60ad603a6b6b23851c3fb0d8/60f850148c03471458e4be28_hithere-poster-00001.jpg) *Image from [Zearn](https://about.zearn.org)*\n\n## Reinforcement Learning Algorithms for Predicting Repeated Behavior\n\nRL: an **agent** learns to make decisions by interacting with an **environment**. Through [trial and error]{.underline}, agent learns the best **actions** to take in different situations to achieve its **goals**.\n\n$$\n\\text{Agent} \\xrightarrow[\\text{Actions}]{\\text{Performs}} \\text{Environment} \\xrightarrow[\\text{Observations, Rewards}]{\\text{Provides}} \\text{Agent}\n$$\n\n**Presenter's Notes:**\n\n-   RL is inspired by the way animals learn from their experiences\n-   An agent in RL represents a decision-maker\n-   Actions: choices made by the agent\n-   Environment: the context in which the agent makes decisions\n-   Observations: information the agent receives about the environment\n-   Rewards: feedback received by the agent based on the actions taken\n\nIn the context of predicting repeated behavior, RL algorithms can be used to model the decision-making process of individuals or groups, such as teachers, by learning from the patterns in their actions and the resulting outcomes.\n\n## Modeling Teachers' Decision-Making Process using Zearn Data\n\nZearn is an online math-teaching platform.\n\n-   Model the decision-making of teachers\n\n-   Understand how they adapt their teaching strategies to optimize student achievement.\n\n**Example:**\n\n-   State: Current progress of students in the class.\n-   Actions: Assigning additional practice, providing personalized feedback, adjusting lesson plans.\n-   Rewards: Improved student performance, student engagement, reduced learning gaps.\n\n$$\nState (S) \\xrightarrow[\\text{Action (A)}]{\\text{Teacher Decides}} New State (S') \\xrightarrow[\\text{Reward (R)}]{\\text{Resulting Outcome}} \\text{Feedback}\n$$\n\n## Data - Zearn Platform\n\nPersonalized learning experience for students. Teachers track student progress and make informed decisions.\n\n-   **Classroom structure:** Self-paced online lessons and small group instruction.\n\n-   **Badge system for student achievement:** Students earn badges upon completing lessons (mastery of specific skills). Track student progress and motivate them to continue learning.\n\n-   **Tower Alerts:** Real-time notifications sent to teachers when a student struggles with a specific concept. Teachers can provide support and address learning gaps.\n\n-   **Teacher selection and criteria:** Consistently use the platform and work in traditional school settings.\n\n-   **Variables of interest:** Teacher effort, student performance, lesson completion, and the time spent by both teachers and students on the platform.\n\n<!-- ![Student View](https://help.zearn.org/hc/article_attachments/5698093595927/HC_-_StudentFeed_3.PNG) -->\n\n<!-- *Image of Zearn's classroom structure* -->\n\n![Badges](https://help.zearn.org/hc/article_attachments/5547000521495/HC_-_LockedLessons.PNG) *Image of the badge system for student achievement*\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n-- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --\nv dplyr     1.1.0     v readr     2.1.4\nv forcats   1.0.0     v stringr   1.5.0\nv ggplot2   3.4.2     v tibble    3.2.1\nv lubridate 1.9.2     v tidyr     1.3.0\nv purrr     1.0.1     \n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\ni Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(PerformanceAnalytics)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: xts\nLoading required package: zoo\n\nAttaching package: 'zoo'\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\n\n################################### WARNING ###################################\n# We noticed you have dplyr installed. The dplyr lag() function breaks how    #\n# base R's lag() function is supposed to work, which breaks lag(my_xts).      #\n#                                                                             #\n# Calls to lag(my_xts) that you enter or source() into this session won't     #\n# work correctly.                                                             #\n#                                                                             #\n# All package code is unaffected because it is protected by the R namespace   #\n# mechanism.                                                                  #\n#                                                                             #\n# Set `options(xts.warn_dplyr_breaks_lag = FALSE)` to suppress this warning.  #\n#                                                                             #\n# You can use stats::lag() to make sure you're not using dplyr::lag(), or you #\n# can add conflictRules('dplyr', exclude = 'lag') to your .Rprofile to stop   #\n# dplyr from breaking base R's lag() function.                                #\n################################### WARNING ###################################\n\nAttaching package: 'xts'\n\nThe following objects are masked from 'package:dplyr':\n\n    first, last\n\n\nAttaching package: 'PerformanceAnalytics'\n\nThe following object is masked from 'package:graphics':\n\n    legend\n```\n:::\n\n```{.r .cell-code}\nlibrary(data.table)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'data.table'\n\nThe following objects are masked from 'package:xts':\n\n    first, last\n\nThe following objects are masked from 'package:lubridate':\n\n    hour, isoweek, mday, minute, month, quarter, second, wday, week,\n    yday, year\n\nThe following objects are masked from 'package:dplyr':\n\n    between, first, last\n\nThe following object is masked from 'package:purrr':\n\n    transpose\n```\n:::\n\n```{.r .cell-code}\n# library(glmnet)\n# library(fastICA)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Transforming data so first week of use = 1 for each teacher\ndf <- read.csv(file = \"Data/df_clean.csv\")\n\n# Convert columns to appropriate data types\ndt <- as.data.table(df)\n# Rename variable\ndt[, `:=`(\n  Classroom.ID = factor(Classroom.ID, exclude = c(\"\")),\n  Teacher.User.ID = factor(Teacher.User.ID, exclude = c(\"\")),\n  Usage.Week = as.Date(Usage.Week),\n  week = week(Usage.Week),\n  Grade.Level = factor(Grade.Level, ordered = TRUE, exclude = c(\"\")),\n  MDR.School.ID = factor(MDR.School.ID),\n  poverty = factor(poverty, ordered = TRUE, exclude = c(\"\")),\n  income = factor(income, ordered = TRUE, exclude = c(\"\")),\n  charter.school = ifelse(charter.school == \"Yes\", 1, ifelse(charter.school == \"No\", 0, NA)),\n  school.account = ifelse(school.account == \"Yes\", 1, ifelse(school.account == \"No\", 0, NA)),\n# Log Transform\n  Minutes.per.Active.User = log(Minutes.per.Active.User + 1),\n  Badges.per.Active.User = log(Badges.per.Active.User + 1),\n  Tower.Alerts.per.Tower.Completion = log(Tower.Alerts.per.Tower.Completion + 1),\n  User.Session = log(User.Session + 1)\n)]\n\n# Create new variables using data.table syntax\ndt[, min_week := week(min(Usage.Week)),\n   by = .(Classroom.ID, Teacher.User.ID)]\ndt[, `:=`(\n  week = ifelse(week >= min_week, week - min_week + 1, week - min_week + 53),\n  Tsubj = max(week),\n  st_login = ifelse(Minutes.per.Active.User > 0, 1, 0),\n  tch_login = ifelse(tch_min > 0, 1, 0),\n  mean_act_st = mean(Active.Users...Total)\n), by = .(Classroom.ID, Teacher.User.ID)]\n```\n:::\n\n\n## Data Selection\n\nWe remove teachers with more than 4 classrooms and those who have logged in for less than 12 weeks in total.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndt <- dt[\n  Tsubj > 12 &\n    teacher_number_classes < 5 &\n    Students...Total > 5 &\n    mean_act_st > 3 &\n    !(month(Usage.Week) %in% c(6, 7, 8)),\n]\n\ncols_to_select <- names(dt)[sapply(dt, function(x) !is.numeric(x) ||\n                                     (is.numeric(x) && is.finite(sd(x)) && sd(x) != 0))]\n\ndt <- dt[, ..cols_to_select]\n```\n:::\n\n\n\n## Descriptive Statistics and Visualizations\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- as.data.frame(dt)\n\ndf_corr <- df  %>%\n  select(Minutes.per.Active.User,\n         Badges.per.Active.User,\n         Tower.Alerts.per.Tower.Completion,\n         User.Session,\n         tch_min)\nchart.Correlation(df_corr, histogram = TRUE, method = \"pearson\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n```\n:::\n\n::: {.cell-output-display}\n![](zearn-pdf_files/figure-pdf/correlations-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n## Change in Active Users and Badges per Active User Over Time\n\n-   8775 classrooms\n-   6187 teachers\n-   20.7791576 students per classroom\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Group data by Classroom.ID or Teacher.User.ID\ngrouped_data <- df %>%\n  group_by(week) %>%\n  summarise(\n    total_active_users = mean(Active.Users...Total),\n    total_badges = mean(Badges.per.Active.User)\n  )\n\n# Visualize the change over time\nggplot(grouped_data, aes(x = week, y = total_active_users)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Active Students Over Time\",\n       x = \"Number of Weeks from First Use\",\n       y = \"Total Active Students\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](zearn-pdf_files/figure-pdf/visualize data-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n## Descriptive Statistics and Visualizations\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate the sum of login values by Usage.Week and Teacher.User.ID\nlogin_data <- df %>%\n  group_by(Usage.Week, Teacher.User.ID) %>%\n  summarize(tch_login = max(tch_login),\n            st_login  = max(st_login)) %>%\n  group_by(Usage.Week) %>%\n  summarize(tch_logins = sum(tch_login),\n            st_logins  = sum(st_login))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`summarise()` has grouped output by 'Usage.Week'. You can override using the\n`.groups` argument.\n```\n:::\n\n```{.r .cell-code}\n# Create bar plot\nbar_plot <- ggplot() +\n  geom_bar(data = login_data, aes(x = Usage.Week, y = st_logins), stat = \"identity\") +\n  geom_point(data = login_data, aes(x = Usage.Week, y = tch_logins), color = \"blue\") +\n  labs(\n    title = \"Mean of Logins Across Teachers' Classrooms\",\n    x = \"Week\",\n    y = \"Total Logins\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  scale_x_date(date_breaks = \"1 week\", date_labels = \"%Y-%m-%d\")\n\n# Add labels for Christmas and Thanksgiving\nbar_plot +\n  geom_text(aes(x = as.Date(\"2019-12-25\"), y = 1250, label = \"Christmas\"),\n            size = 4, angle = 90, hjust = 0.5, vjust = 0.5,\n            color = \"red\") +\n  geom_text(aes(x = as.Date(\"2019-11-25\"), y = 1250, label = \"Thanksgiving\"),\n            size = 4, angle = 90, hjust = 0.5, vjust = 0.5,\n            color = \"orange\")\n```\n\n::: {.cell-output-display}\n![](zearn-pdf_files/figure-pdf/week-by-week-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n## Connecting Variables to Reinforcement Learning Model\n\n**States**\n\n-   Tower Alerts points to how many students are struggling with the content.\n\n-   Minutes per Student / Badges per Student\n\n-   Total Active Students\n\n-   Different combinations of these variables to create unique states.\n\n**Rewards**\n\n-   Learning progress through objective measures such as badges, boosts.\n\n-   Quantify the effectiveness of teacher actions in promoting student learning.\n\n**Actions**\n\n-   Teachers can download resources, engage in different teaching methods or activities.\n\n-   Teachers can choose how much time they spend online.\n\n-   RL optimizes the action selection based on the rewards observed.\n\n    ## Visualizing Relationships Between Variables\n\n-   Use correlation analysis and heatmaps to find relationships between variables\n\n-   Identify variables that may be strong predictors for the reinforcement learning model\n\n**Example: Correlation Chart**\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_corr <- df  %>%\n  select(Badges.per.Active.User,\n         Active.Users...Total,\n         Minutes.per.Active.User,\n         Tower.Alerts.per.Tower.Completion,\n         User.Session)\nchart.Correlation(df_corr, histogram = TRUE, method = \"pearson\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n```\n:::\n\n::: {.cell-output-display}\n![](zearn-pdf_files/figure-pdf/correlation chart-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n## Why Reinforcement Learning?\n\n**Suitability for modeling teacher decision-making**\n\n-   Captures the dynamic and sequential nature of teaching\n\n-   Example: $s_t = (TowerAlerts_t, RD\\_resources\\_t)$, $a_t = (RD\\_small\\_group\\_lessons\\_t, TimeSpent\\_t)$\n\n-   Allows for the exploration of optimal teaching strategies in response to students' progress and engagement\n\n-   Example: Balancing between focusing on struggling students and challenging high-performing students\n\n**Assumptions, objective functions, and tradeoffs**\n\nAssumes teachers make decisions to maximize long-term rewards (e.g., student learning outcomes)\n\nObjective: $\\max_{\\pi} \\mathbb{E}[\\sum_{t=0}^T \\gamma^t r(s_t, a_t) | \\pi]$\n\nBalances the tradeoffs between exploration (trying new teaching strategies) and exploitation (using known effective strategies)\n\nExample: $\\epsilon$-greedy strategy\n\n**Flexibility and robustness**\n\n-   Adapts to changes in the learning environment and individual student needs\n\n-   Example: Adapting to new curriculum or varying levels of student preparedness\n\n-   Allows for the incorporation of various state, action, and reward variables\n\n-   Example: Including external factors such as school policies or testing schedules\n\n-   Can be tailored to different educational contexts and objectives\n\n-   Example: Customizing the model for different grade levels\n\n# Dynamic Analysis (Lau & Glimcher, 2005)\n\n**Introduction to dynamic analysis**\n\n-   Uses response-by-response models to predict choice on each trial based on past reinforcers and choices\n\n-   Based on logistic regression, it captures the linear combination of past reinforcers and choices on each trial\n\n-   Flexible model incorporating effects of past reinforcers, choice history, and biases\n\n**Advantages of dynamic analysis in the context of Zearn dataset**\n\n-   Captures the temporal dependencies and complex interactions between teacher actions, student outcomes, and learning environment\n\n-   Allows for the identification of optimal teaching strategies that evolve over time\n\n-   Enables the evaluation of the impact of various factors (e.g., curriculum, student engagement, etc.) on the decision-making process\n\n-   **Model Formulation**\n\n\n```{=tex}\n\\begin{aligned}\n\\log \\left(\\frac{p_{R, i}}{p_{L, i}}\\right)= & \\sum_{j=1} \\alpha_{ j}( r_{R, i-j}-r_{L, i-j}) \\\\\n& +\\sum_{j=1} \\beta_{j} (c_{R, i-j}-c_{L, i-j})+\\gamma,\n\\end{aligned}\n```\n\n**Preliminary insights and findings**\n\n-   Identification of key factors that influence teacher decision-making and student outcomes\n\n-   Evidence of adaptive teaching strategies that change in response to student progress and engagement\n\n-   Estimation of the relative impact of different teaching actions on student learning\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(stats)\n\n## PCA\ndf_pca <- df %>%\n  select(c(\"RD.elementary_schedule\":\"RD.grade_level_teacher_materials\")) %>%\n  mutate(across(everything(), ~ifelse(is.na(.), 0, .)))\npca <- prcomp(df_pca,\n              center = TRUE,\n              scale. = TRUE)\n# Elbow method\nfactoextra::fviz_eig(pca)\n```\n\n::: {.cell-output-display}\n![](zearn-pdf_files/figure-pdf/pca-1.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\ndf$pca1 <- pca$x[,1]\ndf$pca2 <- pca$x[,2]\ndf$pca3 <- pca$x[,3]\n\ndf_corr <- df %>%\n  select(Badges.per.Active.User,\n         tch_min, pca1, pca2, pca3)\nchart.Correlation(df_corr, histogram = TRUE, method = \"pearson\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n```\n:::\n\n::: {.cell-output-display}\n![](zearn-pdf_files/figure-pdf/pca-2.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\n# ## ICA\n# ica <- fastICA(X = teacher_student_usage_subset[c(14:38)], n.comp=3, row.norm = TRUE)\n# \n# ica.comps <- data.frame(ica$S)\n# cbind(as.data.frame(colnames(teacher_student_usage_subset[c(14:38)])),\n#       t(ica$A))\n# teacher_student_usage_subset$ica1 <- ica.comps$X1\n# teacher_student_usage_subset$ica2 <- ica.comps$X2\n# teacher_student_usage_subset$ica3 <- ica.comps$X3 * -1\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(pglm)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: maxLik\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: miscTools\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nPlease cite the 'maxLik' package as:\nHenningsen, Arne and Toomet, Ott (2011). maxLik: A package for maximum likelihood estimation in R. Computational Statistics 26(3), 443-458. DOI 10.1007/s00180-010-0217-1.\n\nIf you have questions, suggestions, or comments regarding the 'maxLik' package, please use a forum or 'tracker' at maxLik's R-Forge site:\nhttps://r-forge.r-project.org/projects/maxlik/\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: plm\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'plm'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:data.table':\n\n    between\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:dplyr':\n\n    between, lag, lead\n```\n:::\n\n```{.r .cell-code}\nlibrary(performance)\n\n## Minutes Model:\nbase_min <- as.formula(\"Badges.per.Active.User ~ tch_min +\n                        teacher_number_classes + as.factor(Grade.Level) +\n                        Students...Total\")\npanel_min <- plm(base_min, \n                 data = df,\n                 family = 'tobit', effect = \"twoways\",\n                 index = c(\"Classroom.ID\", \"week\", \"Teacher.User.ID\"),\n                 model = \"random\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in pdata.frame(data, index): duplicate couples (id-time) in resulting pdata.frame\n to find out which, use, e.g., table(index(your_pdataframe), useNA = \"ifany\")\n```\n:::\n\n```{.r .cell-code}\n## PCA Model:\nbase_pca <- as.formula(\"Badges.per.Active.User ~ tch_min +\n                        teacher_number_classes + as.factor(Grade.Level) +\n                        Students...Total +\n                        pca1 + pca2 + pca3\")\npanel_pca <- plm(base_pca, \n                 data = df, \n                 family = 'tobit', effect = \"twoways\",\n                 index = c(\"Classroom.ID\", \"week\", \"Teacher.User.ID\"),\n                 model = \"random\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in pdata.frame(data, index): duplicate couples (id-time) in resulting pdata.frame\n to find out which, use, e.g., table(index(your_pdataframe), useNA = \"ifany\")\n```\n:::\n\n```{.r .cell-code}\n# ## Full model:\n# base_full <- as.formula(paste0(\"Badges.per.Active.User ~ User.Session +\n#                          teacher_number_classes + as.factor(Grade.Level) +\n#                          Students...Total +\",\n#                          paste0(names(df[,c(13:33)]), collapse = \" + \")))\n# panel_full <- plm(base_full, \n#                  data = df, \n#                  family = 'tobit',\n#                  index = c(\"Classroom.ID\", \"week\", \"Teacher.User.ID\"),\n#                  model = \"random\")\n\nsummary(panel_min)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTwoways effects Random Effect Model \n   (Swamy-Arora's transformation)\n\nCall:\nplm(formula = base_min, data = df, effect = \"twoways\", model = \"random\", \n    index = c(\"Classroom.ID\", \"week\", \"Teacher.User.ID\"), family = \"tobit\")\n\nUnbalanced Panel: n = 8775, T = 1-163, N = 207347\n\nEffects:\n                   var  std.dev share\nidiosyncratic 0.165945 0.407363 0.673\nindividual    0.078975 0.281024 0.320\ntime          0.001673 0.040899 0.007\ntheta:\n             Min.   1st Qu.    Median      Mean   3rd Qu.      Max.\nid    0.176866502 0.7106719 0.7765961 0.7463369 0.8114442 0.8871860\ntime  0.009929959 0.8599804 0.8707021 0.8637213 0.8778148 0.8898333\ntotal 0.009885495 0.6978995 0.7541231 0.7258397 0.7863539 0.8560842\n\nResiduals:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n -1.717  -0.207   0.210   0.134   0.515   3.237 \n\nCoefficients:\n                            Estimate  Std. Error z-value  Pr(>|z|)    \n(Intercept)               1.1684e+00  4.4398e-02 26.3159 < 2.2e-16 ***\ntch_min                   3.8599e-04  1.9595e-05 19.6979 < 2.2e-16 ***\nteacher_number_classes   -6.9605e-02  9.2290e-03 -7.5420 4.629e-14 ***\nas.factor(Grade.Level).L -9.7438e-01  1.2663e-01 -7.6947 1.419e-14 ***\nas.factor(Grade.Level).Q  1.2529e-01  1.1708e-01  1.0701 0.2845804    \nas.factor(Grade.Level).C -1.3621e-01  1.0757e-01 -1.2663 0.2054139    \nas.factor(Grade.Level)^4  4.1792e-02  1.0245e-01  0.4079 0.6833325    \nas.factor(Grade.Level)^5  1.2836e-01  9.2332e-02  1.3901 0.1644848    \nas.factor(Grade.Level)^6 -2.1945e-01  8.1792e-02 -2.6830 0.0072957 ** \nas.factor(Grade.Level)^7 -1.1774e-02  6.7010e-02 -0.1757 0.8605257    \nas.factor(Grade.Level)^8 -1.6287e-01  4.4647e-02 -3.6479 0.0002644 ***\nas.factor(Grade.Level)^9 -7.6300e-02  2.5183e-02 -3.0298 0.0024469 ** \nStudents...Total         -4.0171e-03  1.1282e-03 -3.5607 0.0003699 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTotal Sum of Squares:    59996\nResidual Sum of Squares: 58680\nR-Squared:      0.08449\nAdj. R-Squared: 0.084437\nChisq: 993.736 on 12 DF, p-value: < 2.22e-16\n```\n:::\n\n```{.r .cell-code}\nsummary(panel_pca)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTwoways effects Random Effect Model \n   (Swamy-Arora's transformation)\n\nCall:\nplm(formula = base_pca, data = df, effect = \"twoways\", model = \"random\", \n    index = c(\"Classroom.ID\", \"week\", \"Teacher.User.ID\"), family = \"tobit\")\n\nUnbalanced Panel: n = 8775, T = 1-163, N = 207347\n\nEffects:\n                   var  std.dev share\nidiosyncratic 0.165526 0.406849 0.678\nindividual    0.077274 0.277981 0.317\ntime          0.001242 0.035248 0.005\ntheta:\n             Min.   1st Qu.    Median      Mean   3rd Qu.      Max.\nid    0.174324751 0.7081112 0.7745449 0.7441327 0.8096865 0.8861091\ntime  0.007422600 0.8382834 0.8505929 0.8427200 0.8587688 0.8726001\ntotal 0.007388543 0.6891224 0.7435851 0.7157397 0.7748565 0.8439257\n\nResiduals:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n -1.740  -0.215   0.197   0.122   0.500   3.240 \n\nCoefficients:\n                            Estimate  Std. Error z-value  Pr(>|z|)    \n(Intercept)               1.1827e+00  4.3424e-02 27.2369 < 2.2e-16 ***\ntch_min                   3.7704e-04  1.9617e-05 19.2198 < 2.2e-16 ***\nteacher_number_classes   -7.0227e-02  9.1535e-03 -7.6722 1.691e-14 ***\nas.factor(Grade.Level).L -9.7639e-01  1.2573e-01 -7.7656 8.124e-15 ***\nas.factor(Grade.Level).Q  1.4074e-01  1.1626e-01  1.2106 0.2260442    \nas.factor(Grade.Level).C -1.3760e-01  1.0680e-01 -1.2884 0.1976191    \nas.factor(Grade.Level)^4  4.0371e-02  1.0173e-01  0.3969 0.6914723    \nas.factor(Grade.Level)^5  1.3007e-01  9.1683e-02  1.4187 0.1559797    \nas.factor(Grade.Level)^6 -2.2078e-01  8.1219e-02 -2.7184 0.0065600 ** \nas.factor(Grade.Level)^7 -8.8656e-03  6.6540e-02 -0.1332 0.8940064    \nas.factor(Grade.Level)^8 -1.6169e-01  4.4328e-02 -3.6475 0.0002648 ***\nas.factor(Grade.Level)^9 -7.4309e-02  2.4988e-02 -2.9738 0.0029415 ** \nStudents...Total         -3.8462e-03  1.1191e-03 -3.4368 0.0005886 ***\npca1                      1.7827e-02  1.6685e-03 10.6848 < 2.2e-16 ***\npca2                     -2.7362e-04  1.7246e-03 -0.1587 0.8739413    \npca3                      4.7709e-03  2.1268e-03  2.2432 0.0248846 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTotal Sum of Squares:    59996\nResidual Sum of Squares: 57467\nR-Squared:      0.093747\nAdj. R-Squared: 0.093682\nChisq: 1121.18 on 15 DF, p-value: < 2.22e-16\n```\n:::\n\n```{.r .cell-code}\n# summary(panel_full)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define the reinforcer, choice, and preference variables\nformula_min <- \"Badges.per.Active.User ~ \"\nformula_PC1 <- \"Badges.per.Active.User ~ \"\nformula_PC2 <- \"Badges.per.Active.User ~ \"\nformula_PC3 <- \"Badges.per.Active.User ~ \"\n\n# Loop through lags t=1 to t=4\nfor (t in 1:4) {\n  # Create lagged action variables\n  df <- df %>%\n    mutate(!!paste0(\"tch_min_\", t) := lag(tch_min, t))\n  \n  # Create lagged PC1 variables\n  df <- df %>%\n    mutate(!!paste0(\"PC1_\", t) := lag(pca1, t))\n  \n  # Create lagged PC2 variables\n  df <- df %>%\n    mutate(!!paste0(\"PC2_\", t) := lag(pca2, t))\n  \n  # Create lagged PC3 variables\n  df <- df %>%\n    mutate(!!paste0(\"PC3_\", t) := lag(pca3, t))\n  \n  # Create lagged Badges.per.Active.User variables\n  df <- df %>%\n    mutate(!!paste0(\"Badges_\", t) := lag(Badges.per.Active.User, t))\n  \n  formula_min <- paste(formula_min, \"Badges_\", t, \" + tch_min_\", t, \" + \", sep = \"\")\n  formula_PC1 <- paste(formula_PC1, \"Badges_\", t, \"+ PC1_\", t, \" + \", sep = \"\")\n  formula_PC2 <- paste(formula_PC2, \"Badges_\", t, \"+ PC2_\", t, \" + \", sep = \"\")\n  formula_PC3 <- paste(formula_PC3, \"Badges_\", t, \"+ PC3_\", t, \" + \", sep = \"\")\n}\n\n# Remove the last \" + \" from the formulas\nformula_min <- substr(formula_min, 1, nchar(formula_min) - 3)\nformula_PC1 <- substr(formula_PC1, 1, nchar(formula_PC1) - 3)\nformula_PC2 <- substr(formula_PC2, 1, nchar(formula_PC2) - 3)\nformula_PC3 <- substr(formula_PC3, 1, nchar(formula_PC3) - 3)\n\n# Convert the strings to formula objects\nformula_min <- as.formula(formula_min)\nformula_PC1 <- as.formula(formula_PC1)\nformula_PC2 <- as.formula(formula_PC2)\nformula_PC3 <- as.formula(formula_PC3)\n\n## Minutes Model:\nlags_min <- plm(formula_min, \n                 data = df,\n                 family = 'tobit', effect = \"twoways\",\n                 index = c(\"Classroom.ID\", \"week\", \"Teacher.User.ID\"),\n                 model = \"random\")\n\n## PCs Models:\nlags_PC1 <- plm(formula_PC1, \n                 data = df,\n                 family = 'tobit', effect = \"twoways\",\n                 index = c(\"Classroom.ID\", \"week\", \"Teacher.User.ID\"),\n                 model = \"random\")\nlags_PC2 <- plm(formula_PC2, \n                 data = df,\n                 family = 'tobit', effect = \"twoways\",\n                 index = c(\"Classroom.ID\", \"week\", \"Teacher.User.ID\"),\n                 model = \"random\")\nlags_PC3 <- plm(formula_PC3, \n                 data = df,\n                 family = 'tobit', effect = \"twoways\",\n                 index = c(\"Classroom.ID\", \"week\", \"Teacher.User.ID\"),\n                 model = \"random\")\nsummary(lags_min, lags_PC1, lags_PC2, lags_PC3)\n```\n:::\n",
    "supporting": [
      "zearn-pdf_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}