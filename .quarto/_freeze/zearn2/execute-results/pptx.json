{
  "hash": "cf708bc7ed786a9d2d8a12d1f6dddd5c",
  "result": {
    "markdown": "---\ntitle: \"Predicting Repeated Behavior in Behavioral Sciences\"\nsubtitle: \"Applying Reinforcement Learning in Teacher Decision-Making\"\nformat: pptx\n---\n\n\n## Predicting Repeated Behavior in Behavioral Sciences\n\nApplying Reinforcement Learning in Teacher Decision-Making\n\n![Teacher and Students](https://assets-global.website-files.com/60ad603a6b6b23851c3fb0d8/60f850148c03471458e4be28_hithere-poster-00001.jpg) *Image from [Zearn](https://about.zearn.org)*\n\n## Reinforcement Learning Algorithms for Predicting Repeated Behavior\n\nRL: an **agent** learns to make decisions by interacting with an **environment**. Through [trial and error]{.underline}, agent learns the best **actions** to take in different situations to achieve its **goals**.\n\n$$\n\\text{Agent} \\xrightarrow[\\text{Actions}]{\\text{Performs}} \\text{Environment} \\xrightarrow[\\text{Observations, Rewards}]{\\text{Provides}} \\text{Agent}\n$$\n\n**Presenter's Notes:**\n\n-   RL is inspired by the way animals learn from their experiences\n-   An agent in RL represents a decision-maker\n-   Actions: choices made by the agent\n-   Environment: the context in which the agent makes decisions\n-   Observations: information the agent receives about the environment\n-   Rewards: feedback received by the agent based on the actions taken\n\nIn the context of predicting repeated behavior, RL algorithms can be used to model the decision-making process of individuals or groups, such as teachers, by learning from the patterns in their actions and the resulting outcomes.\n\n## Modeling Teachers' Decision-Making Process using Zearn Data\n\nZearn is an online math-teaching platform.\n\n-   Model the decision-making of teachers\n\n-   Understand how they adapt their teaching strategies to optimize student achievement.\n\n**Example:**\n\n-   State: Current progress of students in the class.\n-   Actions: Assigning additional practice, providing personalized feedback, adjusting lesson plans.\n-   Rewards: Improved student performance, student engagement, reduced learning gaps.\n\n$$\nState (S) \\xrightarrow[\\text{Action (A)}]{\\text{Teacher Decides}} New State (S') \\xrightarrow[\\text{Reward (R)}]{\\text{Resulting Outcome}} \\text{Feedback}\n$$\n\n## Data - Zearn Platform\n\nPersonalized learning experience for students. Teachers track student progress and make informed decisions.\n\n-   **Classroom structure:** Self-paced online lessons and small group instruction.\n\n-   **Badge system for student achievement:** Students earn badges upon completing lessons (mastery of specific skills). Track student progress and motivate them to continue learning.\n\n-   **Tower Alerts:** Real-time notifications sent to teachers when a student struggles with a specific concept. Teachers can provide support and address learning gaps.\n\n-   **Teacher selection and criteria:** Consistently use the platform and work in traditional school settings.\n\n-   **Variables of interest:** Teacher effort, student performance, lesson completion, and the time spent by both teachers and students on the platform.\n\n<!-- ![Student View](https://help.zearn.org/hc/article_attachments/5698093595927/HC_-_StudentFeed_3.PNG) -->\n\n<!-- *Image of Zearn's classroom structure* -->\n\n![Badges](https://help.zearn.org/hc/article_attachments/5547000521495/HC_-_LockedLessons.PNG) *Image of the badge system for student achievement*\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n## Descriptive Statistics and Visualizations\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](zearn2_files/figure-pptx/unnamed-chunk-2-1.png)\n:::\n:::\n\n\n## Change in Active Users and Badges per Active User Over Time\n\n-   4122 classrooms\n-   2555 teachers\n-   21.1125525 students per classroom\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](zearn2_files/figure-pptx/unnamed-chunk-3-1.png)\n:::\n:::\n\n\n## Descriptive Statistics and Visualizations\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](zearn2_files/figure-pptx/unnamed-chunk-4-1.png)\n:::\n:::\n\n\n## Connecting Variables to Reinforcement Learning Model\n\n**States** - Tower Alerts points to how many students are struggling with the content. - Minutes per Student / Badges per Student - Total Active Students - Different combinations of these variables to create unique states.\n\n**Rewards** - Learning progress through objective measures such as badges, boosts. - Quantify the effectiveness of teacher actions in promoting student learning.\n\n**Actions** - Teachers can download resources, engage in different teaching methods or activities. - Teachers can choose how much time they spend online. - RL optimizes the action selection based on the rewards observed.\n\n## Visualizing Relationships Between Variables\n\n-   Use correlation analysis and heatmaps to find relationships between variables\n-   Identify variables that may be strong predictors for the reinforcement learning model\n\n**Example: Correlation Heatmap**\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](zearn2_files/figure-pptx/unnamed-chunk-5-1.png)\n:::\n:::\n\n\n## Why Reinforcement Learning?\n\n**Suitability for modeling teacher decision-making** - Captures the dynamic and sequential nature of teaching - Example: $s_t = (TowerAlerts_t, RD\\_resources\\_t)$, $a_t = (RD\\_small\\_group\\_lessons\\_t, TimeSpent\\_t)$ - Allows for the exploration of optimal teaching strategies in response to students' progress and engagement - Example: Balancing between focusing on struggling students and challenging high-performing students\n\n**Assumptions, objective functions, and tradeoffs** - Assumes teachers make decisions to maximize long-term rewards (e.g., student learning outcomes) - Objective: $\\max_{\\pi} \\mathbb{E}[\\sum_{t=0}^T \\gamma^t r(s_t, a_t) | \\pi]$ - Balances the tradeoffs between exploration (trying new teaching strategies) and exploitation (using known effective strategies) - Example: $\\epsilon$-greedy strategy\n\n**Flexibility and robustness** - Adapts to changes in the learning environment and individual student needs - Example: Adapting to new curriculum or varying levels of student preparedness - Allows for the incorporation of various state, action, and reward variables - Example: Including external factors such as school policies or testing schedules - Can be tailored to different educational contexts and objectives - Example: Customizing the model for different grade levels or subject areas\n\n# Dynamic Analysis (Lau & Glimcher, 2005)\n\n**Introduction to dynamic analysis** - Uses response-by-response models to predict choice on each trial based on past reinforcers and choices - Based on logistic regression, it captures the linear combination of past reinforcers and choices on each trial - Flexible model incorporating effects of past reinforcers, choice history, and biases\n\n**Advantages of dynamic analysis in the context of Zearn dataset** - Captures the temporal dependencies and complex interactions between teacher actions, student outcomes, and learning environment - Allows for the identification of optimal teaching strategies that evolve over time - Enables the evaluation of the impact of various factors (e.g., curriculum, student engagement, etc.) on the decision-making process\n\n**Model Formulation**\n\n\n```{=tex}\n\\begin{aligned}\n\\log \\left(\\frac{p_{R, i}}{p_{L, i}}\\right)= & \\sum_{j=1} \\alpha_{ j}( r_{R, i-j}-r_{L, i-j}) \\\\\n& +\\sum_{j=1} \\beta_{j} (c_{R, i-j}-c_{L, i-j})+\\gamma,\n\\end{aligned}\n```\n\n**Preliminary insights and findings** - Identification of key factors that influence teacher decision-making and student outcomes - Evidence of adaptive teaching strategies that change in response to student progress and engagement - Estimation of the relative impact of different teaching actions on student learning\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](zearn2_files/figure-pptx/unnamed-chunk-6-1.png)\n:::\n:::",
    "supporting": [
      "zearn2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}